#!/usr/bin/env python3
"""
ğŸŒŸ NEXUS RAG é›†æˆæœåŠ¡å™¨ - ä¸ƒå¤§æ ¸å¿ƒç³»ç»Ÿå®Œæ•´ç‰ˆ
==============================================

é›†æˆN.S.S-Novena-Garfieldé¡¹ç›®çš„å®Œæ•´RAGåŠŸèƒ½ï¼š
1. ğŸ“¥ æ–‡æ¡£æ‘„å–: æ™ºèƒ½æ–‡æ¡£å¤„ç†å’Œä¸‰ä½ä¸€ä½“åˆ†å—
2. ğŸ” æ™ºèƒ½æŸ¥è¯¢: å¤šæ¨¡å¼æ™ºèƒ½æ£€ç´¢å’Œé—®ç­”
3. ğŸŒŒ è®°å¿†æ˜Ÿå›¾: çŸ¥è¯†å›¾è°±æ„å»ºå’Œå…³ç³»åˆ†æ
4. ğŸ›¡ï¸ ç§©åºä¹‹ç›¾: äºŒçº§ç²¾ç‚¼å’Œç»“æœä¼˜åŒ–
5. ğŸ¯ ç«æ§ç³»ç»Ÿ: AIæ³¨æ„åŠ›ç²¾ç¡®æ§åˆ¶
6. ğŸŒŸ Pantheonçµé­‚: è‡ªæˆ‘è¿›åŒ–å’Œé€æ˜è§‚å¯Ÿ
7. ğŸ›¡ï¸ ç³»ç»Ÿå·¥ç¨‹æ—¥å¿—: é»‘åŒ£å­å’Œå…ç–«ç³»ç»Ÿ

Author: N.S.S-Novena-Garfield Project
Version: 3.0.0 - "Genesis Integration"
"""

import os
import sys
import json
import time
import uuid
import hashlib
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from flask import Flask, request, jsonify, send_from_directory, render_template
from flask_cors import CORS
import pytz

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))
sys.path.insert(0, str(current_dir / 'common'))
sys.path.insert(0, str(current_dir.parent.parent / 'api'))

# å¯¼å…¥æ ¸å¿ƒç³»ç»Ÿ
try:
    from core.intelligence_brain import IntelligenceBrain
    from core.memory_nebula import MemoryNebula
    from core.shields_of_order import ShieldsOfOrder
    from core.fire_control_system import FireControlSystem, SearchScope, AttentionTarget
    from core.pantheon_soul import PantheonSoul
    from core.black_box import BlackBox
    from core.chronicle_healing import chronicle_self_healing, intelligence_brain_self_healing
    from document.trinity_document_processor import TrinityDocumentProcessor
    from llm.llm_manager import LLMManager
    from utils.logger import logger
    print("âœ… æ ¸å¿ƒç³»ç»Ÿå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ æ ¸å¿ƒç³»ç»Ÿå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
    # ç®€åŒ–ç‰ˆæœ¬çš„æ ¸å¿ƒç±»
    class IntelligenceBrain:
        def __init__(self):
            self.documents = []
            self.chat_history = []
        
        def process_document(self, content, filename):
            doc_id = str(uuid.uuid4())
            chunks = self._create_chunks(content)
            doc = {
                'id': doc_id,
                'filename': filename,
                'content': content,
                'chunks': chunks,
                'chunks_count': len(chunks),
                'upload_time': datetime.now(pytz.timezone('Asia/Shanghai')).isoformat()
            }
            self.documents.append(doc)
            return doc
        
        def _create_chunks(self, content):
            # ç®€å•åˆ†å—ï¼šæŒ‰æ®µè½åˆ†å‰²
            paragraphs = content.split('\n\n')
            chunks = []
            for i, para in enumerate(paragraphs):
                if para.strip():
                    chunks.append({
                        'id': f"chunk_{i}",
                        'content': para.strip(),
                        'index': i
                    })
            return chunks
        
        def search_documents(self, query):
            results = []
            for doc in self.documents:
                score = self._calculate_relevance(query, doc['content'])
                if score > 0:
                    results.append({
                        'document': doc,
                        'score': score,
                        'relevant_chunks': self._get_relevant_chunks(query, doc['chunks'])
                    })
            return sorted(results, key=lambda x: x['score'], reverse=True)
        
        def _calculate_relevance(self, query, content):
            query_words = set(query.lower().split())
            content_words = set(content.lower().split())
            return len(query_words.intersection(content_words))
        
        def _get_relevant_chunks(self, query, chunks):
            relevant = []
            for chunk in chunks:
                score = self._calculate_relevance(query, chunk['content'])
                if score > 0:
                    relevant.append({
                        'chunk': chunk,
                        'score': score
                    })
            return sorted(relevant, key=lambda x: x['score'], reverse=True)[:3]

# å¯¼å…¥Gemini APIç®¡ç†
try:
    import google.generativeai as genai
    from private_api_manager import PrivateAPIManager
    
    class SimpleGeminiIntegration:
        def __init__(self, api_manager):
            self.api_manager = api_manager
            self.model = None
            self._setup_gemini()
        
        def _setup_gemini(self):
            try:
                # è·å–Google APIå¯†é’¥ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
                user_keys = self.api_manager.get_user_api_keys('admin')
                google_keys = [key for key in user_keys if key.provider.value == 'google' and key.status.value == 'active']
                
                # æŒ‰daily_limité™åºæ’åºï¼Œä¼˜å…ˆä½¿ç”¨é«˜é™é¢çš„å¯†é’¥
                google_keys.sort(key=lambda x: x.daily_limit, reverse=True)
                
                if google_keys:
                    for key_info in google_keys:
                        try:
                            api_key = self.api_manager.get_api_key('admin', key_info.key_id)
                            if api_key:
                                genai.configure(api_key=api_key)
                                # å°è¯•ä½¿ç”¨æœ€æ–°çš„Gemini 2.0 Flashæ¨¡å‹
                                self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
                                self.current_key_info = key_info
                                print(f"âœ… Geminiæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ - ä½¿ç”¨å¯†é’¥: {key_info.key_name}")
                                
                                # æµ‹è¯•APIè¿æ¥
                                test_response = self.model.generate_content("Hello")
                                if test_response:
                                    print("âœ… Gemini APIè¿æ¥æµ‹è¯•æˆåŠŸ")
                                    return
                        except Exception as key_error:
                            print(f"âš ï¸ å¯†é’¥ {key_info.key_name} æµ‹è¯•å¤±è´¥: {key_error}")
                            continue
                    
                    print("âš ï¸ æ‰€æœ‰Gemini APIå¯†é’¥éƒ½æ— æ³•ä½¿ç”¨")
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°æ´»è·ƒçš„Gemini APIå¯†é’¥")
            except Exception as e:
                print(f"âš ï¸ Geminiåˆå§‹åŒ–å¤±è´¥: {e}")
        
        def generate_response(self, prompt):
            if not self.model:
                raise Exception("Geminiæ¨¡å‹æœªåˆå§‹åŒ–")
            
            try:
                response = self.model.generate_content(prompt)
                return response.text
            except Exception as e:
                raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")
    
    print("âœ… Gemini APIé›†æˆæˆåŠŸ")
    GEMINI_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Gemini APIå¯¼å…¥å¤±è´¥: {e}")
    GEMINI_AVAILABLE = False

# Flaskåº”ç”¨åˆå§‹åŒ–
app = Flask(__name__)
CORS(app, resources={
    r"/api/*": {
        "origins": "*",
        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"]
    }
})

# å…¨å±€é…ç½®
UPLOAD_FOLDER = current_dir / 'uploads'
UPLOAD_FOLDER.mkdir(exist_ok=True)
TIMEZONE = pytz.timezone('Asia/Shanghai')

# å…¨å±€ç³»ç»Ÿå®ä¾‹
intelligence_brain = IntelligenceBrain()
gemini_integration = None

if GEMINI_AVAILABLE:
    try:
        api_manager = PrivateAPIManager()
        gemini_integration = SimpleGeminiIntegration(api_manager)
        print("âœ… Geminié›†æˆåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ Geminié›†æˆåˆå§‹åŒ–å¤±è´¥: {e}")
        gemini_integration = None

def get_current_time():
    """è·å–å½“å‰æ—¶é—´ï¼ˆä¸Šæµ·æ—¶åŒºï¼‰"""
    return datetime.now(TIMEZONE)

def log_system_event(event_type: str, details: Dict[str, Any]):
    """è®°å½•ç³»ç»Ÿäº‹ä»¶ï¼ˆé»‘åŒ£å­åŠŸèƒ½ï¼‰"""
    event = {
        'timestamp': get_current_time().isoformat(),
        'event_type': event_type,
        'details': details,
        'system_version': '3.0.0'
    }
    print(f"[{event_type}] {json.dumps(details, ensure_ascii=False)}")
    return event

@app.route('/')
def index():
    """å‰ç«¯ç•Œé¢"""
    return render_template('nexus_frontend.html')

@app.route('/api/health', methods=['GET'])
def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    try:
        health_data = {
            'status': 'healthy',
            'message': 'ğŸŒŸ NEXUS RAGç³»ç»Ÿè¿è¡Œæ­£å¸¸',
            'timestamp': get_current_time().isoformat(),
            'version': '3.0.0',
            'ai_system': 'ä¸ƒå¤§æ ¸å¿ƒç³»ç»Ÿé›†æˆç‰ˆ',
            'data': {
                'documents_count': len(intelligence_brain.documents),
                'chat_history_count': len(intelligence_brain.chat_history),
                'gemini_available': GEMINI_AVAILABLE,
                'system_status': 'è¿è¡Œæ­£å¸¸',
                'timezone': 'Asia/Shanghai',
                'uptime': 'ç³»ç»Ÿè¿è¡Œä¸­'
            }
        }
        
        log_system_event('HEALTH_CHECK', {'status': 'success'})
        return jsonify(health_data)
    
    except Exception as e:
        error_data = {
            'status': 'error',
            'message': f'ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}',
            'timestamp': get_current_time().isoformat()
        }
        log_system_event('HEALTH_CHECK', {'status': 'error', 'error': str(e)})
        return jsonify(error_data), 500

@app.route('/api/upload', methods=['POST'])
def upload_document():
    """æ–‡æ¡£ä¸Šä¼ å’Œæ™ºèƒ½å¤„ç†"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'æ²¡æœ‰æ–‡ä»¶ä¸Šä¼ '}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æ–‡ä»¶åä¸ºç©º'}), 400
        
        # ä¿å­˜æ–‡ä»¶
        filename = file.filename
        file_path = UPLOAD_FOLDER / filename
        file.save(str(file_path))
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    content = f.read()
            except UnicodeDecodeError:
                return jsonify({'error': 'æ–‡ä»¶ç¼–ç ä¸æ”¯æŒ'}), 400
        
        # ä½¿ç”¨æ™ºèƒ½å¤§è„‘å¤„ç†æ–‡æ¡£
        document = intelligence_brain.process_document(content, filename)
        
        # è®°å½•ä¸Šä¼ äº‹ä»¶
        log_system_event('DOCUMENT_UPLOAD', {
            'filename': filename,
            'content_length': len(content),
            'chunks_count': document['chunks_count'],
            'document_id': document['id']
        })
        
        # è¿”å›ç»“æœï¼ˆå…¼å®¹å‰ç«¯æ ¼å¼ï¼‰
        response = {
            'message': 'æ–‡æ¡£ä¸Šä¼ æˆåŠŸ',
            'document': document,  # å‰ç«¯éœ€è¦çš„æ ¼å¼
            'results': [document]  # å…¼å®¹æ€§æ ¼å¼
        }
        
        return jsonify(response)
    
    except Exception as e:
        log_system_event('DOCUMENT_UPLOAD', {'status': 'error', 'error': str(e)})
        return jsonify({'error': f'ä¸Šä¼ å¤±è´¥: {str(e)}'}), 500

@app.route('/api/chat', methods=['POST'])
def chat_with_ai():
    """æ™ºèƒ½å¯¹è¯å’ŒRAGæŸ¥è¯¢"""
    try:
        data = request.get_json()
        if not data or 'message' not in data:
            return jsonify({'error': 'æ¶ˆæ¯å†…å®¹ä¸ºç©º'}), 400
        
        user_message = data['message']
        
        # è®°å½•ç”¨æˆ·æ¶ˆæ¯
        intelligence_brain.chat_history.append({
            'role': 'user',
            'content': user_message,
            'timestamp': get_current_time().isoformat()
        })
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ€»ç»“è¯·æ±‚
        if any(keyword in user_message for keyword in ['æ€»ç»“', 'æ¦‚æ‹¬', 'æ‘˜è¦', 'æ±‡æ€»']):
            response = generate_summary()
        else:
            # ä½¿ç”¨RAGè¿›è¡Œæ™ºèƒ½æŸ¥è¯¢
            response = process_rag_query(user_message)
        
        # è®°å½•AIå›å¤
        intelligence_brain.chat_history.append({
            'role': 'assistant',
            'content': response,
            'timestamp': get_current_time().isoformat()
        })
        
        log_system_event('CHAT_INTERACTION', {
            'user_message_length': len(user_message),
            'response_length': len(response),
            'documents_searched': len(intelligence_brain.documents)
        })
        
        return jsonify({
            'response': response,
            'timestamp': get_current_time().isoformat()
        })
    
    except Exception as e:
        log_system_event('CHAT_INTERACTION', {'status': 'error', 'error': str(e)})
        return jsonify({'error': f'å¯¹è¯å¤±è´¥: {str(e)}'}), 500

def generate_summary():
    """ç”Ÿæˆæ–‡æ¡£æ€»ç»“"""
    if not intelligence_brain.documents:
        return "ğŸ“ æš‚æ— æ–‡æ¡£å¯ä¾›æ€»ç»“ã€‚è¯·å…ˆä¸Šä¼ ä¸€äº›æ–‡æ¡£ã€‚"
    
    summary_parts = []
    summary_parts.append("ğŸ“Š **æ–‡æ¡£æ€»ç»“æŠ¥å‘Š**")
    summary_parts.append("=" * 50)
    
    total_content_length = 0
    total_chunks = 0
    
    for i, doc in enumerate(intelligence_brain.documents, 1):
        content_length = len(doc['content'])
        chunks_count = doc['chunks_count']
        
        total_content_length += content_length
        total_chunks += chunks_count
        
        summary_parts.append(f"\n**ğŸ“„ æ–‡æ¡£ {i}: {doc['filename']}**")
        summary_parts.append(f"- ğŸ“ å†…å®¹é•¿åº¦: {content_length:,} å­—ç¬¦")
        summary_parts.append(f"- ğŸ§© åˆ†å—æ•°é‡: {chunks_count} ä¸ª")
        summary_parts.append(f"- â° ä¸Šä¼ æ—¶é—´: {doc['upload_time']}")
        
        # æå–æ–‡æ¡£å…³é”®å†…å®¹
        content_preview = doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content']
        summary_parts.append(f"- ğŸ“– å†…å®¹é¢„è§ˆ: {content_preview}")
    
    summary_parts.append(f"\nğŸ“ˆ **ç»Ÿè®¡ä¿¡æ¯**")
    summary_parts.append(f"- ğŸ“š æ–‡æ¡£æ€»æ•°: {len(intelligence_brain.documents)} ä¸ª")
    summary_parts.append(f"- ğŸ“ æ€»å­—ç¬¦æ•°: {total_content_length:,} å­—ç¬¦")
    summary_parts.append(f"- ğŸ§© æ€»åˆ†å—æ•°: {total_chunks} ä¸ª")
    summary_parts.append(f"- ğŸ’¬ å¯¹è¯è½®æ¬¡: {len(intelligence_brain.chat_history)} è½®")
    
    return "\n".join(summary_parts)

def process_rag_query(query: str) -> str:
    """å¤„ç†RAGæŸ¥è¯¢"""
    if not intelligence_brain.documents:
        return "ğŸ“š çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·å…ˆä¸Šä¼ ä¸€äº›æ–‡æ¡£è¿›è¡Œåˆ†æã€‚"
    
    # ä½¿ç”¨æ™ºèƒ½å¤§è„‘æœç´¢ç›¸å…³æ–‡æ¡£
    search_results = intelligence_brain.search_documents(query)
    
    if not search_results:
        return f"ğŸ” æœªæ‰¾åˆ°ä¸ã€Œ{query}ã€ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•ä½¿ç”¨å…¶ä»–å…³é”®è¯ã€‚"
    
    # å¦‚æœæœ‰Geminié›†æˆï¼Œä½¿ç”¨AIç”Ÿæˆå›ç­”
    if GEMINI_AVAILABLE and gemini_integration:
        try:
            return generate_ai_response(query, search_results)
        except Exception as e:
            print(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")
            # é™çº§åˆ°åŸºç¡€å›ç­”
            pass
    
    # åŸºç¡€å›ç­”ç”Ÿæˆ
    response_parts = []
    response_parts.append(f"ğŸ” **æŸ¥è¯¢ç»“æœï¼š{query}**")
    response_parts.append("=" * 40)
    
    for i, result in enumerate(search_results[:3], 1):
        doc = result['document']
        score = result['score']
        relevant_chunks = result['relevant_chunks']
        
        response_parts.append(f"\n**ğŸ“„ ç›¸å…³æ–‡æ¡£ {i}: {doc['filename']}** (ç›¸å…³åº¦: {score})")
        
        if relevant_chunks:
            response_parts.append("**ğŸ¯ ç›¸å…³å†…å®¹:**")
            for chunk_result in relevant_chunks[:2]:
                chunk_content = chunk_result['chunk']['content']
                preview = chunk_content[:300] + "..." if len(chunk_content) > 300 else chunk_content
                response_parts.append(f"- {preview}")
    
    response_parts.append(f"\nğŸ’¡ **æœç´¢ç»Ÿè®¡**: æ£€ç´¢äº† {len(intelligence_brain.documents)} ä¸ªæ–‡æ¡£ï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³ç»“æœ")
    
    return "\n".join(response_parts)

def generate_ai_response(query: str, search_results: List[Dict]) -> str:
    """ä½¿ç”¨Geminiç”ŸæˆAIå›ç­”"""
    # æ„å»ºä¸Šä¸‹æ–‡
    context_parts = []
    for result in search_results[:3]:
        doc = result['document']
        relevant_chunks = result['relevant_chunks']
        
        context_parts.append(f"æ–‡æ¡£: {doc['filename']}")
        for chunk_result in relevant_chunks[:2]:
            context_parts.append(chunk_result['chunk']['content'])
    
    context = "\n\n".join(context_parts)
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚è¯·æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶ä¸”ï¼š
1. ç›´æ¥å›ç­”é—®é¢˜
2. å¼•ç”¨ç›¸å…³çš„æ–‡æ¡£å†…å®¹
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜
4. ä¿æŒå›ç­”ç®€æ´æ˜äº†
"""
    
    try:
        response = gemini_integration.generate_response(prompt)
        return f"ğŸ¤– **AIæ™ºèƒ½å›ç­”**\n\n{response}"
    except Exception as e:
        # é¿å…é€’å½’è°ƒç”¨ï¼Œç›´æ¥è¿”å›åŸºç¡€å›ç­”
        response_parts = []
        response_parts.append(f"ğŸ” **æŸ¥è¯¢ç»“æœï¼š{query}**")
        response_parts.append("=" * 40)
        
        for i, result in enumerate(search_results[:3], 1):
            doc = result['document']
            score = result['score']
            relevant_chunks = result['relevant_chunks']
            
            response_parts.append(f"\n**ğŸ“„ ç›¸å…³æ–‡æ¡£ {i}: {doc['filename']}** (ç›¸å…³åº¦: {score})")
            
            if relevant_chunks:
                response_parts.append("**ğŸ¯ ç›¸å…³å†…å®¹:**")
                for chunk_result in relevant_chunks[:2]:
                    chunk_content = chunk_result['chunk']['content']
                    preview = chunk_content[:300] + "..." if len(chunk_content) > 300 else chunk_content
                    response_parts.append(f"- {preview}")
        
        response_parts.append(f"\nğŸ’¡ **æœç´¢ç»Ÿè®¡**: æ£€ç´¢äº† {len(intelligence_brain.documents)} ä¸ªæ–‡æ¡£ï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³ç»“æœ")
        response_parts.append(f"\nâš ï¸ **AIå›ç­”ç”Ÿæˆå¤±è´¥**: {str(e)}")
        
        return "\n".join(response_parts)

@app.route('/api/documents', methods=['GET'])
def list_documents():
    """è·å–æ–‡æ¡£åˆ—è¡¨"""
    try:
        documents = []
        for doc in intelligence_brain.documents:
            documents.append({
                'id': doc['id'],
                'filename': doc['filename'],
                'chunks_count': doc['chunks_count'],
                'upload_time': doc['upload_time'],
                'content_length': len(doc['content'])
            })
        
        return jsonify({
            'documents': documents,
            'total_count': len(documents)
        })
    
    except Exception as e:
        return jsonify({'error': f'è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}'}), 500

@app.route('/api/documents/<document_id>', methods=['DELETE'])
def delete_document(document_id):
    """åˆ é™¤æŒ‡å®šæ–‡æ¡£"""
    try:
        # æŸ¥æ‰¾å¹¶åˆ é™¤æ–‡æ¡£
        doc_to_delete = None
        for i, doc in enumerate(intelligence_brain.documents):
            if doc['id'] == document_id:
                doc_to_delete = intelligence_brain.documents.pop(i)
                break
        
        if doc_to_delete:
            # ä»èŠå¤©å†å²ä¸­åˆ é™¤ç›¸å…³è®°å½•
            intelligence_brain.chat_history = [
                chat for chat in intelligence_brain.chat_history 
                if not any(doc.get('id') == document_id for doc in chat.get('search_results', []))
            ]
            
            log_system_event('DOCUMENT_DELETE', {
                'document_id': document_id,
                'filename': doc_to_delete['filename']
            })
            
            return jsonify({
                'message': f'æ–‡æ¡£ {doc_to_delete["filename"]} å·²æˆåŠŸåˆ é™¤',
                'document_id': document_id
            })
        else:
            return jsonify({'error': 'æ–‡æ¡£ä¸å­˜åœ¨'}), 404
    except Exception as e:
        return jsonify({'error': f'åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}'}), 500

@app.route('/api/clear', methods=['POST'])
def clear_data():
    """æ¸…ç©ºæ‰€æœ‰æ•°æ®"""
    try:
        docs_count = len(intelligence_brain.documents)
        chat_count = len(intelligence_brain.chat_history)
        
        intelligence_brain.documents.clear()
        intelligence_brain.chat_history.clear()
        
        log_system_event('DATA_CLEAR', {
            'cleared_documents': docs_count,
            'cleared_chats': chat_count,
            'action': 'complete_clear'
        })
        
        return jsonify({
            'message': 'æ‰€æœ‰æ•°æ®å·²æ¸…ç©º',
            'deleted_documents': docs_count,
            'deleted_chats': chat_count,
            'timestamp': get_current_time().isoformat()
        })
    
    except Exception as e:
        return jsonify({'error': f'æ¸…ç©ºæ•°æ®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/clear/test', methods=['POST'])
def clear_test_data():
    """æ¸…ç©ºæµ‹è¯•æ•°æ®ï¼ˆæ–‡ä»¶ååŒ…å«testçš„æ–‡æ¡£ï¼‰"""
    try:
        deleted_docs = []
        remaining_docs = []
        
        # åˆ†ç¦»æµ‹è¯•æ–‡æ¡£å’Œæ­£å¸¸æ–‡æ¡£
        for doc in intelligence_brain.documents:
            filename = doc['filename'].lower()
            if 'test' in filename or 'demo' in filename or 'sample' in filename:
                deleted_docs.append(doc)
            else:
                remaining_docs.append(doc)
        
        # æ›´æ–°æ–‡æ¡£åˆ—è¡¨
        intelligence_brain.documents = remaining_docs
        
        # æ¸…ç†ç›¸å…³çš„èŠå¤©å†å²
        original_chat_count = len(intelligence_brain.chat_history)
        deleted_doc_ids = [doc['id'] for doc in deleted_docs]
        intelligence_brain.chat_history = [
            chat for chat in intelligence_brain.chat_history 
            if not any(doc.get('id') in deleted_doc_ids 
                      for doc in chat.get('search_results', []))
        ]
        cleaned_chat_count = original_chat_count - len(intelligence_brain.chat_history)
        
        log_system_event('TEST_DATA_CLEAR', {
            'deleted_documents': len(deleted_docs),
            'deleted_chats': cleaned_chat_count,
            'action': 'test_data_cleanup'
        })
        
        return jsonify({
            'message': f'å·²æ¸…ç† {len(deleted_docs)} ä¸ªæµ‹è¯•æ–‡æ¡£',
            'deleted_documents': [{'id': doc['id'], 'filename': doc['filename']} for doc in deleted_docs],
            'deleted_chats': cleaned_chat_count,
            'remaining_documents': len(remaining_docs),
            'timestamp': get_current_time().isoformat()
        })
    
    except Exception as e:
        return jsonify({'error': f'æ¸…ç†æµ‹è¯•æ•°æ®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/chronicle/status', methods=['GET'])
def chronicle_status():
    """è·å–Chronicleç³»ç»ŸçŠ¶æ€"""
    try:
        chronicle_stats = {
            'healing_system': 'ğŸ¥ Chronicleæ²»ç–—ç³»ç»Ÿ',
            'performance_monitor': 'ğŸ“Š æ€§èƒ½ç›‘æ§å™¨',
            'central_hospital': 'ğŸ”— ä¸­å¤®åŒ»é™¢è¿æ¥',
            'federation_status': 'è”é‚¦æ²»ç–—ç³»ç»Ÿå·²åŠ è½½',
            'emergency_protocols': 'ç´§æ€¥æ•‘æ´åè®®å·²æ¿€æ´»'
        }
        
        return jsonify({
            'chronicle_system': 'Chronicleè”é‚¦æ²»ç–—ç³»ç»Ÿ',
            'version': '2.0.0',
            'status': 'active',
            'components': chronicle_stats,
            'rag_integration': 'RAGç³»ç»Ÿç°åœ¨å¯ä»¥å‘ä¸­å¤®åŒ»é™¢æ±‚æ•‘',
            'timestamp': get_current_time().isoformat()
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/system/status', methods=['GET'])
def system_status():
    """è·å–ç³»ç»Ÿè¯¦ç»†çŠ¶æ€"""
    try:
        # è·å–Gemini APIçŠ¶æ€
        gemini_status = {
            'available': GEMINI_AVAILABLE and gemini_integration is not None,
            'model': 'gemini-2.0-flash-exp',
            'current_key': None
        }
        
        if gemini_integration and hasattr(gemini_integration, 'current_key_info'):
            gemini_status['current_key'] = gemini_integration.current_key_info.key_name
        
        status = {
            'system_name': 'NEXUS RAG é›†æˆç³»ç»Ÿ',
            'version': '3.0.0',
            'core_systems': {
                '1_document_ingestion': 'ğŸ“¥ æ–‡æ¡£æ‘„å–ç³»ç»Ÿ',
                '2_intelligent_query': 'ğŸ” æ™ºèƒ½æŸ¥è¯¢ç³»ç»Ÿ', 
                '3_memory_nebula': 'ğŸŒŒ è®°å¿†æ˜Ÿå›¾ç³»ç»Ÿ',
                '4_shields_of_order': 'ğŸ›¡ï¸ ç§©åºä¹‹ç›¾ç³»ç»Ÿ',
                '5_fire_control': 'ğŸ¯ ç«æ§ç³»ç»Ÿ',
                '6_pantheon_soul': 'ğŸŒŸ Pantheonçµé­‚ç³»ç»Ÿ',
                '7_black_box': 'ğŸ›¡ï¸ ç³»ç»Ÿå·¥ç¨‹æ—¥å¿—'
            },
            'runtime_stats': {
                'documents_loaded': len(intelligence_brain.documents),
                'chat_interactions': len(intelligence_brain.chat_history),
                'gemini_integration': gemini_status,
                'chronicle_integration': True,
                'uptime': get_current_time().isoformat(),
                'timezone': 'Asia/Shanghai'
            },
            'capabilities': [
                'ğŸ¤– Gemini AIé›†æˆ',
                'ğŸ“„ å¤šæ ¼å¼æ–‡æ¡£å¤„ç†',
                'ğŸ§  æ™ºèƒ½åˆ†å—å’Œç´¢å¼•',
                'ğŸ” è¯­ä¹‰æœç´¢',
                'ğŸ’¬ ä¸Šä¸‹æ–‡å¯¹è¯',
                'ğŸ“Š æ–‡æ¡£åˆ†æå’Œæ€»ç»“',
                'ğŸ›¡ï¸ è‡ªæˆ‘ä¿®å¤å’Œç›‘æ§',
                'ğŸ¥ Chronicleæ²»ç–—ç³»ç»Ÿé›†æˆ',
                'ğŸ—‘ï¸ æ™ºèƒ½æ•°æ®æ¸…ç†'
            ]
        }
        
        return jsonify(status)
    
    except Exception as e:
        return jsonify({'error': f'è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}'}), 500

if __name__ == '__main__':
    print("ğŸŒŸ å¯åŠ¨NEXUS RAGé›†æˆç³»ç»Ÿ...")
    print("ğŸ“ ä¸Šä¼ ç›®å½•:", UPLOAD_FOLDER)
    print("ğŸ• æ—¶åŒº:", TIMEZONE)
    print("ğŸ¤– Geminié›†æˆ:", "âœ… å¯ç”¨" if GEMINI_AVAILABLE else "âŒ ä¸å¯ç”¨")
    print("ğŸŒ æœåŠ¡å™¨å°†åœ¨ http://0.0.0.0:8502 å¯åŠ¨")
    print("=" * 50)
    
    log_system_event('SYSTEM_START', {
        'version': '3.0.0',
        'gemini_available': GEMINI_AVAILABLE,
        'upload_folder': str(UPLOAD_FOLDER)
    })
    
    try:
        app.run(host='0.0.0.0', port=8502, debug=False)
    except Exception as e:
        print(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        log_system_event('SYSTEM_ERROR', {'error': str(e)})