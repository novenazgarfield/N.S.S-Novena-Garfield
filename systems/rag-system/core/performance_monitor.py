"""
ğŸ“Š Chronicleè”é‚¦æ€§èƒ½ç›‘æ§å™¨ (Chronicle Federation Performance Monitor)
====================================================================

ç›‘æ§RAGç³»ç»Ÿä¸Chronicleè”é‚¦çš„æ€§èƒ½æŒ‡æ ‡
- APIå“åº”æ—¶é—´ç›‘æ§
- å†…å­˜ä½¿ç”¨ç›‘æ§
- æ•…éšœå¤„ç†æ€§èƒ½
- ç½‘ç»œå»¶è¿Ÿç»Ÿè®¡

Author: N.S.S-Novena-Garfield Project
Version: 2.0.0 - "Chronicle Federation Performance"
"""

import time
import psutil
import asyncio
import statistics
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from collections import deque
import json

from utils.logger import logger

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: datetime = field(default_factory=datetime.now)
    api_response_time: float = 0.0
    memory_usage_mb: float = 0.0
    cpu_usage_percent: float = 0.0
    network_latency_ms: float = 0.0
    success_rate: float = 1.0
    error_count: int = 0

@dataclass
class PerformanceThresholds:
    """æ€§èƒ½é˜ˆå€¼é…ç½®"""
    max_api_response_time: float = 5.0  # 5ç§’
    max_memory_usage_mb: float = 500.0  # 500MB
    max_cpu_usage_percent: float = 80.0  # 80%
    max_network_latency_ms: float = 100.0  # 100ms
    min_success_rate: float = 0.95  # 95%

class ChroniclePerformanceMonitor:
    """Chronicleè”é‚¦æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, max_history: int = 1000):
        self.max_history = max_history
        self.metrics_history: deque = deque(maxlen=max_history)
        self.thresholds = PerformanceThresholds()
        self.start_time = datetime.now()
        self.total_requests = 0
        self.failed_requests = 0
        self.api_times: deque = deque(maxlen=100)
        self.network_latencies: deque = deque(maxlen=100)
        
        logger.info("ğŸ“Š Chronicleè”é‚¦æ€§èƒ½ç›‘æ§å™¨å·²å¯åŠ¨")
    
    def record_api_call(self, response_time: float, success: bool = True):
        """è®°å½•APIè°ƒç”¨æ€§èƒ½"""
        self.total_requests += 1
        self.api_times.append(response_time)
        
        if not success:
            self.failed_requests += 1
        
        # æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
        if response_time > self.thresholds.max_api_response_time:
            logger.warning(f"âš ï¸ APIå“åº”æ—¶é—´è¶…é˜ˆå€¼: {response_time:.2f}s > {self.thresholds.max_api_response_time}s")
    
    def record_network_latency(self, latency_ms: float):
        """è®°å½•ç½‘ç»œå»¶è¿Ÿ"""
        self.network_latencies.append(latency_ms)
        
        if latency_ms > self.thresholds.max_network_latency_ms:
            logger.warning(f"âš ï¸ ç½‘ç»œå»¶è¿Ÿè¶…é˜ˆå€¼: {latency_ms:.2f}ms > {self.thresholds.max_network_latency_ms}ms")
    
    def collect_system_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        try:
            # è·å–å½“å‰è¿›ç¨‹ä¿¡æ¯
            process = psutil.Process()
            
            # å†…å­˜ä½¿ç”¨
            memory_info = process.memory_info()
            memory_usage_mb = memory_info.rss / 1024 / 1024
            
            # CPUä½¿ç”¨ç‡
            cpu_usage = process.cpu_percent()
            
            # APIå“åº”æ—¶é—´ç»Ÿè®¡
            avg_api_time = statistics.mean(self.api_times) if self.api_times else 0.0
            
            # ç½‘ç»œå»¶è¿Ÿç»Ÿè®¡
            avg_network_latency = statistics.mean(self.network_latencies) if self.network_latencies else 0.0
            
            # æˆåŠŸç‡è®¡ç®—
            success_rate = (self.total_requests - self.failed_requests) / max(self.total_requests, 1)
            
            metrics = PerformanceMetrics(
                api_response_time=avg_api_time,
                memory_usage_mb=memory_usage_mb,
                cpu_usage_percent=cpu_usage,
                network_latency_ms=avg_network_latency,
                success_rate=success_rate,
                error_count=self.failed_requests
            )
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.metrics_history.append(metrics)
            
            # æ£€æŸ¥é˜ˆå€¼
            self._check_thresholds(metrics)
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
            return PerformanceMetrics()
    
    def _check_thresholds(self, metrics: PerformanceMetrics):
        """æ£€æŸ¥æ€§èƒ½é˜ˆå€¼"""
        warnings = []
        
        if metrics.memory_usage_mb > self.thresholds.max_memory_usage_mb:
            warnings.append(f"å†…å­˜ä½¿ç”¨è¶…é˜ˆå€¼: {metrics.memory_usage_mb:.1f}MB")
        
        if metrics.cpu_usage_percent > self.thresholds.max_cpu_usage_percent:
            warnings.append(f"CPUä½¿ç”¨è¶…é˜ˆå€¼: {metrics.cpu_usage_percent:.1f}%")
        
        if metrics.success_rate < self.thresholds.min_success_rate:
            warnings.append(f"æˆåŠŸç‡ä½äºé˜ˆå€¼: {metrics.success_rate:.1%}")
        
        for warning in warnings:
            logger.warning(f"âš ï¸ {warning}")
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics_history:
            return {"status": "no_data", "message": "æš‚æ— æ€§èƒ½æ•°æ®"}
        
        recent_metrics = list(self.metrics_history)[-10:]  # æœ€è¿‘10ä¸ªæŒ‡æ ‡
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_api_time = statistics.mean([m.api_response_time for m in recent_metrics])
        avg_memory = statistics.mean([m.memory_usage_mb for m in recent_metrics])
        avg_cpu = statistics.mean([m.cpu_usage_percent for m in recent_metrics])
        avg_latency = statistics.mean([m.network_latency_ms for m in recent_metrics])
        current_success_rate = recent_metrics[-1].success_rate if recent_metrics else 0
        
        # è¿è¡Œæ—¶é—´
        uptime = datetime.now() - self.start_time
        
        return {
            "status": "operational",
            "uptime_seconds": uptime.total_seconds(),
            "total_requests": self.total_requests,
            "failed_requests": self.failed_requests,
            "success_rate": current_success_rate,
            "performance": {
                "avg_api_response_time": avg_api_time,
                "avg_memory_usage_mb": avg_memory,
                "avg_cpu_usage_percent": avg_cpu,
                "avg_network_latency_ms": avg_latency
            },
            "thresholds": {
                "api_response_time": self.thresholds.max_api_response_time,
                "memory_usage_mb": self.thresholds.max_memory_usage_mb,
                "cpu_usage_percent": self.thresholds.max_cpu_usage_percent,
                "network_latency_ms": self.thresholds.max_network_latency_ms,
                "min_success_rate": self.thresholds.min_success_rate
            },
            "last_updated": datetime.now().isoformat()
        }
    
    def get_performance_trends(self, minutes: int = 60) -> Dict[str, List[float]]:
        """è·å–æ€§èƒ½è¶‹åŠ¿æ•°æ®"""
        cutoff_time = datetime.now() - timedelta(minutes=minutes)
        recent_metrics = [
            m for m in self.metrics_history 
            if m.timestamp >= cutoff_time
        ]
        
        if not recent_metrics:
            return {"message": f"è¿‡å»{minutes}åˆ†é’Ÿå†…æ— æ•°æ®"}
        
        return {
            "timestamps": [m.timestamp.isoformat() for m in recent_metrics],
            "api_response_times": [m.api_response_time for m in recent_metrics],
            "memory_usage": [m.memory_usage_mb for m in recent_metrics],
            "cpu_usage": [m.cpu_usage_percent for m in recent_metrics],
            "network_latency": [m.network_latency_ms for m in recent_metrics],
            "success_rates": [m.success_rate for m in recent_metrics]
        }
    
    def export_metrics(self, filepath: str):
        """å¯¼å‡ºæ€§èƒ½æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        try:
            metrics_data = {
                "export_time": datetime.now().isoformat(),
                "summary": self.get_performance_summary(),
                "trends": self.get_performance_trends(minutes=1440),  # 24å°æ—¶
                "raw_metrics": [
                    {
                        "timestamp": m.timestamp.isoformat(),
                        "api_response_time": m.api_response_time,
                        "memory_usage_mb": m.memory_usage_mb,
                        "cpu_usage_percent": m.cpu_usage_percent,
                        "network_latency_ms": m.network_latency_ms,
                        "success_rate": m.success_rate,
                        "error_count": m.error_count
                    }
                    for m in self.metrics_history
                ]
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(metrics_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡å·²å¯¼å‡ºåˆ°: {filepath}")
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºæ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
    
    async def start_monitoring(self, interval_seconds: int = 30):
        """å¯åŠ¨æŒç»­ç›‘æ§"""
        logger.info(f"ğŸ”„ å¼€å§‹æŒç»­æ€§èƒ½ç›‘æ§ï¼Œé—´éš”: {interval_seconds}ç§’")
        
        try:
            while True:
                metrics = self.collect_system_metrics()
                logger.debug(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡: å†…å­˜={metrics.memory_usage_mb:.1f}MB, "
                           f"CPU={metrics.cpu_usage_percent:.1f}%, "
                           f"API={metrics.api_response_time:.2f}s")
                
                await asyncio.sleep(interval_seconds)
                
        except asyncio.CancelledError:
            logger.info("â¹ï¸ æ€§èƒ½ç›‘æ§å·²åœæ­¢")
        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½ç›‘æ§å¼‚å¸¸: {e}")

# å…¨å±€æ€§èƒ½ç›‘æ§å™¨å®ä¾‹
_performance_monitor = None

def get_performance_monitor() -> ChroniclePerformanceMonitor:
    """è·å–æ€§èƒ½ç›‘æ§å™¨å•ä¾‹"""
    global _performance_monitor
    if _performance_monitor is None:
        _performance_monitor = ChroniclePerformanceMonitor()
    return _performance_monitor

# æ€§èƒ½ç›‘æ§è£…é¥°å™¨
def monitor_performance(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    import functools
    
    @functools.wraps(func)
    async def async_wrapper(*args, **kwargs):
        monitor = get_performance_monitor()
        start_time = time.time()
        success = True
        
        try:
            if asyncio.iscoroutinefunction(func):
                result = await func(*args, **kwargs)
            else:
                result = func(*args, **kwargs)
            return result
        except Exception as e:
            success = False
            raise
        finally:
            end_time = time.time()
            response_time = end_time - start_time
            monitor.record_api_call(response_time, success)
    
    @functools.wraps(func)
    def sync_wrapper(*args, **kwargs):
        monitor = get_performance_monitor()
        start_time = time.time()
        success = True
        
        try:
            result = func(*args, **kwargs)
            return result
        except Exception as e:
            success = False
            raise
        finally:
            end_time = time.time()
            response_time = end_time - start_time
            monitor.record_api_call(response_time, success)
    
    # æ ¹æ®å‡½æ•°ç±»å‹è¿”å›ç›¸åº”çš„åŒ…è£…å™¨
    if asyncio.iscoroutinefunction(func):
        return async_wrapper
    else:
        return sync_wrapper

# ä¾¿æ·å‡½æ•°
def log_performance_summary():
    """è®°å½•æ€§èƒ½æ‘˜è¦"""
    monitor = get_performance_monitor()
    summary = monitor.get_performance_summary()
    
    logger.info("ğŸ“Š Chronicleè”é‚¦æ€§èƒ½æ‘˜è¦:")
    logger.info(f"   è¿è¡Œæ—¶é—´: {summary.get('uptime_seconds', 0):.0f}ç§’")
    logger.info(f"   æ€»è¯·æ±‚æ•°: {summary.get('total_requests', 0)}")
    logger.info(f"   æˆåŠŸç‡: {summary.get('success_rate', 0):.1%}")
    
    perf = summary.get('performance', {})
    logger.info(f"   å¹³å‡APIå“åº”: {perf.get('avg_api_response_time', 0):.2f}s")
    logger.info(f"   å¹³å‡å†…å­˜ä½¿ç”¨: {perf.get('avg_memory_usage_mb', 0):.1f}MB")
    logger.info(f"   å¹³å‡CPUä½¿ç”¨: {perf.get('avg_cpu_usage_percent', 0):.1f}%")

logger.info("ğŸ“Š Chronicleè”é‚¦æ€§èƒ½ç›‘æ§å™¨å·²åŠ è½½")