"""
AIæ¨¡å‹é›†æˆæ¨¡å—
æ”¯æŒå¤šç§AIæ¨¡å‹çš„ç»Ÿä¸€æ¥å£ï¼ŒåŒ…æ‹¬OpenAIã€Claudeã€Geminiç­‰
"""

import os
import sys
import time
import json
from typing import Dict, List, Any, Optional, Tuple
from enum import Enum
from dataclasses import dataclass
import streamlit as st

# æ·»åŠ APIç®¡ç†è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'api_management'))

try:
    from config.private_api_manager import PrivateAPIManager, APIProvider, get_user_api_key
    API_MANAGER_AVAILABLE = True
except ImportError:
    API_MANAGER_AVAILABLE = False

# å¯¼å…¥å„ç§AIæ¨¡å‹çš„SDK
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    CLAUDE_AVAILABLE = True
except ImportError:
    CLAUDE_AVAILABLE = False

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

class ModelProvider(Enum):
    """AIæ¨¡å‹æä¾›å•†"""
    OPENAI = "openai"
    CLAUDE = "claude"
    GEMINI = "gemini"
    LOCAL = "local"
    DEMO = "demo"

@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®"""
    name: str
    provider: ModelProvider
    model_id: str
    max_tokens: int = 2048
    temperature: float = 0.7
    supports_streaming: bool = True
    supports_images: bool = False
    cost_per_1k_tokens: float = 0.0
    description: str = ""

class AIModelManager:
    """AIæ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.available_models = self._init_available_models()
        self.current_model = None
        self.api_manager = PrivateAPIManager() if API_MANAGER_AVAILABLE else None
    
    def _init_available_models(self) -> Dict[str, ModelConfig]:
        """åˆå§‹åŒ–å¯ç”¨æ¨¡å‹"""
        models = {}
        
        # OpenAIæ¨¡å‹
        if OPENAI_AVAILABLE:
            models.update({
                "gpt-4": ModelConfig(
                    name="GPT-4",
                    provider=ModelProvider.OPENAI,
                    model_id="gpt-4",
                    max_tokens=4096,
                    temperature=0.7,
                    supports_streaming=True,
                    supports_images=True,
                    cost_per_1k_tokens=0.03,
                    description="OpenAIæœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œé€‚åˆå¤æ‚æ¨ç†ä»»åŠ¡"
                ),
                "gpt-3.5-turbo": ModelConfig(
                    name="GPT-3.5 Turbo",
                    provider=ModelProvider.OPENAI,
                    model_id="gpt-3.5-turbo",
                    max_tokens=4096,
                    temperature=0.7,
                    supports_streaming=True,
                    supports_images=False,
                    cost_per_1k_tokens=0.002,
                    description="OpenAIé«˜æ€§ä»·æ¯”æ¨¡å‹ï¼Œé€‚åˆæ—¥å¸¸å¯¹è¯"
                )
            })
        
        # Claudeæ¨¡å‹
        if CLAUDE_AVAILABLE:
            models.update({
                "claude-3-opus": ModelConfig(
                    name="Claude-3 Opus",
                    provider=ModelProvider.CLAUDE,
                    model_id="claude-3-opus-20240229",
                    max_tokens=4096,
                    temperature=0.7,
                    supports_streaming=True,
                    supports_images=True,
                    cost_per_1k_tokens=0.015,
                    description="Anthropicæœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œæ“…é•¿åˆ†æå’Œåˆ›ä½œ"
                ),
                "claude-3-sonnet": ModelConfig(
                    name="Claude-3 Sonnet",
                    provider=ModelProvider.CLAUDE,
                    model_id="claude-3-sonnet-20240229",
                    max_tokens=4096,
                    temperature=0.7,
                    supports_streaming=True,
                    supports_images=True,
                    cost_per_1k_tokens=0.003,
                    description="Anthropicå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬çš„æ¨¡å‹"
                )
            })
        
        # Geminiæ¨¡å‹
        if GEMINI_AVAILABLE:
            models.update({
                "gemini-2.0-flash": ModelConfig(
                    name="Gemini 2.0 Flash",
                    provider=ModelProvider.GEMINI,
                    model_id="gemini-2.0-flash-exp",
                    max_tokens=8192,
                    temperature=0.7,
                    supports_streaming=True,
                    supports_images=True,
                    cost_per_1k_tokens=0.001,
                    description="Googleæœ€æ–°çš„Geminiæ¨¡å‹ï¼Œé€Ÿåº¦å¿«ï¼Œæ€§èƒ½å¼º"
                ),
                "gemini-1.5-pro": ModelConfig(
                    name="Gemini 1.5 Pro",
                    provider=ModelProvider.GEMINI,
                    model_id="gemini-1.5-pro",
                    max_tokens=8192,
                    temperature=0.7,
                    supports_streaming=True,
                    supports_images=True,
                    cost_per_1k_tokens=0.002,
                    description="Google Geminiä¸“ä¸šç‰ˆï¼Œé€‚åˆå¤æ‚ä»»åŠ¡"
                )
            })
        
        # æ¼”ç¤ºæ¨¡å‹ï¼ˆæ€»æ˜¯å¯ç”¨ï¼‰
        models["demo"] = ModelConfig(
            name="æ¼”ç¤ºæ¨¡å‹",
            provider=ModelProvider.DEMO,
            model_id="demo",
            max_tokens=2048,
            temperature=0.7,
            supports_streaming=False,
            supports_images=False,
            cost_per_1k_tokens=0.0,
            description="å†…ç½®æ¼”ç¤ºæ¨¡å‹ï¼Œæ— éœ€APIå¯†é’¥"
        )
        
        return models
    
    def get_available_models(self, user_id: str = None) -> Dict[str, ModelConfig]:
        """è·å–ç”¨æˆ·å¯ç”¨çš„æ¨¡å‹"""
        if not user_id or not self.api_manager:
            # åªè¿”å›æ¼”ç¤ºæ¨¡å‹
            return {"demo": self.available_models["demo"]}
        
        available = {"demo": self.available_models["demo"]}
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰å¯¹åº”çš„APIå¯†é’¥
        user_keys = self.api_manager.get_user_api_keys(user_id)
        
        for key_info in user_keys:
            if key_info.status.value == "active":
                provider = key_info.provider.value
                
                # æä¾›å•†åç§°æ˜ å°„
                provider_mapping = {
                    "google": "gemini",
                    "openai": "openai", 
                    "anthropic": "claude"
                }
                
                mapped_provider = provider_mapping.get(provider, provider)
                
                # æ ¹æ®APIæä¾›å•†æ·»åŠ å¯¹åº”æ¨¡å‹
                for model_key, model_config in self.available_models.items():
                    if model_config.provider.value == mapped_provider:
                        available[model_key] = model_config
        
        return available
    
    def select_model(self, model_key: str, user_id: str = None) -> bool:
        """é€‰æ‹©æ¨¡å‹"""
        if model_key not in self.available_models:
            return False
        
        model_config = self.available_models[model_key]
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™ä½¿ç”¨è¯¥æ¨¡å‹
        if model_config.provider != ModelProvider.DEMO:
            if not user_id or not self.api_manager:
                return False
            
            # æä¾›å•†åç§°åå‘æ˜ å°„
            reverse_provider_mapping = {
                "gemini": "google",
                "openai": "openai",
                "claude": "anthropic"
            }
            
            api_provider = reverse_provider_mapping.get(model_config.provider.value, model_config.provider.value)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„APIå¯†é’¥
            api_result = get_user_api_key(user_id, api_provider)
            if not api_result:
                return False
        
        self.current_model = model_config
        return True
    
    def generate_response(self, prompt: str, context: str = "", user_id: str = None, **kwargs) -> str:
        """ç”ŸæˆAIå›å¤"""
        if not self.current_model:
            return "âŒ è¯·å…ˆé€‰æ‹©ä¸€ä¸ªAIæ¨¡å‹"
        
        try:
            if self.current_model.provider == ModelProvider.DEMO:
                return self._generate_demo_response(prompt, context)
            elif self.current_model.provider == ModelProvider.OPENAI:
                return self._generate_openai_response(prompt, context, user_id, **kwargs)
            elif self.current_model.provider == ModelProvider.CLAUDE:
                return self._generate_claude_response(prompt, context, user_id, **kwargs)
            elif self.current_model.provider == ModelProvider.GEMINI:
                return self._generate_gemini_response(prompt, context, user_id, **kwargs)
            else:
                return "âŒ ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹"
        
        except Exception as e:
            return f"âŒ ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {str(e)}"
    
    def _generate_demo_response(self, prompt: str, context: str = "") -> str:
        """ç”Ÿæˆæ¼”ç¤ºå›å¤"""
        # æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´
        time.sleep(1)
        
        # åŸºäºå…³é”®è¯çš„ç®€å•å›å¤
        if "ä½ å¥½" in prompt or "hello" in prompt.lower():
            return "ğŸ‘‹ æ‚¨å¥½ï¼æˆ‘æ˜¯RAGæ™ºèƒ½åŠ©æ‰‹çš„æ¼”ç¤ºæ¨¡å¼ã€‚æˆ‘å¯ä»¥å¸®æ‚¨å›ç­”é—®é¢˜å’Œåˆ†ææ–‡æ¡£ã€‚"
        
        if "æ–‡æ¡£" in prompt or "åˆ†æ" in prompt:
            if context:
                return f"ğŸ“„ åŸºäºæ‚¨ä¸Šä¼ çš„æ–‡æ¡£ï¼Œæˆ‘å‘ç°ä»¥ä¸‹è¦ç‚¹ï¼š\n\n{context[:300]}...\n\nè¿™æ˜¯æ–‡æ¡£çš„ä¸»è¦å†…å®¹ã€‚æ‚¨æƒ³äº†è§£å“ªä¸ªå…·ä½“æ–¹é¢ï¼Ÿ"
            else:
                return "ğŸ“„ è¯·å…ˆä¸Šä¼ æ–‡æ¡£ï¼Œæˆ‘å°±å¯ä»¥ä¸ºæ‚¨åˆ†ææ–‡æ¡£å†…å®¹äº†ã€‚"
        
        if "RAG" in prompt.upper():
            return """ğŸ” **RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯ä»‹ç»ï¼š**

RAGæ˜¯ä¸€ç§ç»“åˆäº†ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬ç”Ÿæˆçš„AIæŠ€æœ¯ï¼š

1. **æ£€ç´¢é˜¶æ®µ**ï¼šä»çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯
2. **å¢å¼ºé˜¶æ®µ**ï¼šå°†æ£€ç´¢ç»“æœä½œä¸ºä¸Šä¸‹æ–‡
3. **ç”Ÿæˆé˜¶æ®µ**ï¼šåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå‡†ç¡®å›ç­”

**ä¼˜åŠ¿ï¼š**
- æé«˜å›ç­”å‡†ç¡®æ€§
- å‡å°‘å¹»è§‰é—®é¢˜
- æ”¯æŒå®æ—¶ä¿¡æ¯æ›´æ–°
- å¯è§£é‡Šæ€§å¼º"""
        
        # é»˜è®¤å›å¤
        return f"""ğŸ’­ **æ‚¨çš„é—®é¢˜ï¼š** {prompt}

ğŸ¤– **æ¼”ç¤ºæ¨¡å¼å›å¤ï¼š**
æ„Ÿè°¢æ‚¨çš„æé—®ï¼è¿™æ˜¯æ¼”ç¤ºæ¨¡å¼çš„å›å¤ã€‚åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæ‚¨å¯ä»¥ï¼š

1. ğŸ”‘ é…ç½®APIå¯†é’¥ä½¿ç”¨çœŸå®çš„AIæ¨¡å‹
2. ğŸ“„ ä¸Šä¼ æ–‡æ¡£è¿›è¡Œæ™ºèƒ½åˆ†æ
3. ğŸ’¬ è¿›è¡Œæ›´æ·±å…¥çš„å¯¹è¯äº¤æµ

å¦‚éœ€ä½¿ç”¨å®Œæ•´åŠŸèƒ½ï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®æ‚¨çš„APIå¯†é’¥ã€‚"""
    
    def _generate_openai_response(self, prompt: str, context: str = "", user_id: str = None, **kwargs) -> str:
        """ç”ŸæˆOpenAIå›å¤"""
        if not OPENAI_AVAILABLE or not user_id or not self.api_manager:
            return "âŒ OpenAIåŠŸèƒ½ä¸å¯ç”¨"
        
        # è·å–APIå¯†é’¥
        api_result = get_user_api_key(user_id, "openai")
        if not api_result:
            return "âŒ æœªæ‰¾åˆ°å¯ç”¨çš„OpenAI APIå¯†é’¥"
        
        key_id, api_key = api_result
        
        try:
            # é…ç½®OpenAIå®¢æˆ·ç«¯
            client = openai.OpenAI(api_key=api_key)
            
            # æ„å»ºæ¶ˆæ¯
            messages = []
            if context:
                messages.append({
                    "role": "system",
                    "content": f"åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š\n\n{context}"
                })
            
            messages.append({
                "role": "user",
                "content": prompt
            })
            
            # è°ƒç”¨API
            response = client.chat.completions.create(
                model=self.current_model.model_id,
                messages=messages,
                max_tokens=kwargs.get('max_tokens', self.current_model.max_tokens),
                temperature=kwargs.get('temperature', self.current_model.temperature)
            )
            
            # è®°å½•ä½¿ç”¨
            self.api_manager.record_api_usage(user_id, key_id)
            
            return response.choices[0].message.content
        
        except Exception as e:
            return f"âŒ OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def _generate_claude_response(self, prompt: str, context: str = "", user_id: str = None, **kwargs) -> str:
        """ç”ŸæˆClaudeå›å¤"""
        if not CLAUDE_AVAILABLE or not user_id or not self.api_manager:
            return "âŒ ClaudeåŠŸèƒ½ä¸å¯ç”¨"
        
        # è·å–APIå¯†é’¥
        api_result = get_user_api_key(user_id, "claude")
        if not api_result:
            return "âŒ æœªæ‰¾åˆ°å¯ç”¨çš„Claude APIå¯†é’¥"
        
        key_id, api_key = api_result
        
        try:
            # é…ç½®Claudeå®¢æˆ·ç«¯
            client = anthropic.Anthropic(api_key=api_key)
            
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            content = prompt
            if context:
                content = f"åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š\n\n{context}\n\né—®é¢˜ï¼š{prompt}"
            
            # è°ƒç”¨API
            response = client.messages.create(
                model=self.current_model.model_id,
                max_tokens=kwargs.get('max_tokens', self.current_model.max_tokens),
                temperature=kwargs.get('temperature', self.current_model.temperature),
                messages=[{
                    "role": "user",
                    "content": content
                }]
            )
            
            # è®°å½•ä½¿ç”¨
            self.api_manager.record_api_usage(user_id, key_id)
            
            return response.content[0].text
        
        except Exception as e:
            return f"âŒ Claude APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def _generate_gemini_response(self, prompt: str, context: str = "", user_id: str = None, **kwargs) -> str:
        """ç”ŸæˆGeminiå›å¤"""
        if not GEMINI_AVAILABLE or not user_id or not self.api_manager:
            return "âŒ GeminiåŠŸèƒ½ä¸å¯ç”¨"
        
        # è·å–APIå¯†é’¥
        api_result = get_user_api_key(user_id, "google")
        if not api_result:
            return "âŒ æœªæ‰¾åˆ°å¯ç”¨çš„Gemini APIå¯†é’¥"
        
        key_id, api_key = api_result
        
        try:
            # é…ç½®Gemini
            genai.configure(api_key=api_key)
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            model = genai.GenerativeModel(self.current_model.model_id)
            
            # æ„å»ºæç¤º
            full_prompt = prompt
            if context:
                full_prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

æ–‡æ¡£å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{prompt}

è¯·åŸºäºæ–‡æ¡£å†…å®¹æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜å¹¶æä¾›ä¸€èˆ¬æ€§çš„å›ç­”ã€‚"""
            
            # é…ç½®ç”Ÿæˆå‚æ•°
            generation_config = genai.types.GenerationConfig(
                max_output_tokens=kwargs.get('max_tokens', self.current_model.max_tokens),
                temperature=kwargs.get('temperature', self.current_model.temperature),
            )
            
            # ç”Ÿæˆå›å¤
            response = model.generate_content(
                full_prompt,
                generation_config=generation_config
            )
            
            # è®°å½•ä½¿ç”¨
            self.api_manager.record_api_usage(user_id, key_id)
            
            return response.text
        
        except Exception as e:
            return f"âŒ Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def get_model_info(self) -> Optional[ModelConfig]:
        """è·å–å½“å‰æ¨¡å‹ä¿¡æ¯"""
        return self.current_model
    
    def get_usage_stats(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·çš„APIä½¿ç”¨ç»Ÿè®¡"""
        if not self.api_manager or not user_id:
            return {}
        
        return self.api_manager.get_usage_statistics(user_id)

# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
ai_model_manager = AIModelManager()

def get_ai_model_manager() -> AIModelManager:
    """è·å–AIæ¨¡å‹ç®¡ç†å™¨å®ä¾‹"""
    return ai_model_manager

def render_model_selector(user_id: str = None) -> str:
    """æ¸²æŸ“æ¨¡å‹é€‰æ‹©å™¨"""
    manager = get_ai_model_manager()
    available_models = manager.get_available_models(user_id)
    
    if not available_models:
        st.error("âŒ æ²¡æœ‰å¯ç”¨çš„AIæ¨¡å‹")
        return None
    
    # æ¨¡å‹é€‰æ‹©
    model_options = {}
    for key, config in available_models.items():
        icon = "ğŸ¤–" if config.provider == ModelProvider.DEMO else "ğŸ§ "
        cost_info = f" (${config.cost_per_1k_tokens:.3f}/1K tokens)" if config.cost_per_1k_tokens > 0 else " (å…è´¹)"
        model_options[key] = f"{icon} {config.name}{cost_info}"
    
    selected_key = st.selectbox(
        "ğŸ¤– é€‰æ‹©AIæ¨¡å‹",
        options=list(model_options.keys()),
        format_func=lambda x: model_options[x],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
    )
    
    if selected_key:
        if manager.select_model(selected_key, user_id):
            model_info = manager.get_model_info()
            if model_info:
                st.success(f"âœ… å·²é€‰æ‹©æ¨¡å‹: {model_info.name}")
                
                # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
                with st.expander("ğŸ“Š æ¨¡å‹è¯¦æƒ…", expanded=False):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**æä¾›å•†**: {model_info.provider.value}")
                        st.write(f"**æœ€å¤§ä»¤ç‰Œ**: {model_info.max_tokens}")
                        st.write(f"**æ”¯æŒæµå¼**: {'âœ…' if model_info.supports_streaming else 'âŒ'}")
                    with col2:
                        st.write(f"**æ”¯æŒå›¾åƒ**: {'âœ…' if model_info.supports_images else 'âŒ'}")
                        st.write(f"**æˆæœ¬**: ${model_info.cost_per_1k_tokens:.3f}/1K tokens")
                    
                    st.write(f"**æè¿°**: {model_info.description}")
                
                return selected_key
        else:
            st.error("âŒ æ¨¡å‹é€‰æ‹©å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
    
    return None

def render_api_key_manager(user_id: str):
    """æ¸²æŸ“APIå¯†é’¥ç®¡ç†ç•Œé¢"""
    if not API_MANAGER_AVAILABLE:
        st.error("âŒ APIç®¡ç†åŠŸèƒ½ä¸å¯ç”¨")
        return
    
    st.markdown("### ğŸ”‘ APIå¯†é’¥ç®¡ç†")
    
    manager = PrivateAPIManager()
    
    # æ˜¾ç¤ºç°æœ‰å¯†é’¥
    user_keys = manager.get_user_api_keys(user_id)
    
    if user_keys:
        st.markdown("**ğŸ“‹ æ‚¨çš„APIå¯†é’¥:**")
        for key_info in user_keys:
            with st.expander(f"{key_info.provider.value.upper()} - {key_info.key_name}", expanded=False):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.write(f"**çŠ¶æ€**: {key_info.status.value}")
                    st.write(f"**ä½¿ç”¨æ¬¡æ•°**: {key_info.usage_count}")
                with col2:
                    st.write(f"**æ—¥é™åˆ¶**: {key_info.daily_limit}")
                    st.write(f"**æœˆé™åˆ¶**: {key_info.monthly_limit}")
                with col3:
                    if st.button(f"åˆ é™¤", key=f"delete_{key_info.key_id}"):
                        if manager.remove_api_key(user_id, key_info.key_id):
                            st.success("âœ… å¯†é’¥å·²åˆ é™¤")
                            st.rerun()
                        else:
                            st.error("âŒ åˆ é™¤å¤±è´¥")
    
    # æ·»åŠ æ–°å¯†é’¥
    st.markdown("**â• æ·»åŠ æ–°çš„APIå¯†é’¥:**")
    
    with st.form("add_api_key"):
        col1, col2 = st.columns(2)
        with col1:
            provider = st.selectbox(
                "æä¾›å•†",
                options=["openai", "google", "claude"],
                format_func=lambda x: {
                    "openai": "ğŸ¤– OpenAI",
                    "google": "ğŸ” Google (Gemini)",
                    "claude": "ğŸ§  Anthropic (Claude)"
                }[x]
            )
        
        with col2:
            key_name = st.text_input("å¯†é’¥åç§°", placeholder="ä¾‹å¦‚ï¼šæˆ‘çš„OpenAIå¯†é’¥")
        
        api_key = st.text_input("APIå¯†é’¥", type="password", placeholder="è¾“å…¥æ‚¨çš„APIå¯†é’¥")
        
        col1, col2 = st.columns(2)
        with col1:
            daily_limit = st.number_input("æ—¥ä½¿ç”¨é™åˆ¶", min_value=10, max_value=10000, value=1000)
        with col2:
            monthly_limit = st.number_input("æœˆä½¿ç”¨é™åˆ¶", min_value=100, max_value=100000, value=30000)
        
        description = st.text_area("æè¿°ï¼ˆå¯é€‰ï¼‰", placeholder="æè¿°è¿™ä¸ªAPIå¯†é’¥çš„ç”¨é€”")
        
        if st.form_submit_button("ğŸ”‘ æ·»åŠ å¯†é’¥", type="primary"):
            if not key_name or not api_key:
                st.error("âŒ è¯·å¡«å†™å¯†é’¥åç§°å’ŒAPIå¯†é’¥")
            else:
                try:
                    from config.private_api_manager import APIProvider
                    provider_enum = APIProvider(provider)
                    key_id = manager.add_api_key(
                        user_id=user_id,
                        provider=provider_enum,
                        key_name=key_name,
                        api_key=api_key,
                        daily_limit=daily_limit,
                        monthly_limit=monthly_limit,
                        description=description
                    )
                    
                    if key_id:
                        st.success(f"âœ… APIå¯†é’¥æ·»åŠ æˆåŠŸï¼ID: {key_id}")
                        st.rerun()
                    else:
                        st.error("âŒ æ·»åŠ å¤±è´¥ï¼Œå¯èƒ½æ˜¯å¯†é’¥åç§°é‡å¤")
                except Exception as e:
                    st.error(f"âŒ æ·»åŠ å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    manager = AIModelManager()
    print("å¯ç”¨æ¨¡å‹:")
    for key, config in manager.get_available_models().items():
        print(f"- {key}: {config.name} ({config.provider.value})")