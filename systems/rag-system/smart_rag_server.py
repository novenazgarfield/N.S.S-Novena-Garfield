#!/usr/bin/env python3
"""
æ™ºèƒ½RAGç³»ç»ŸæœåŠ¡å™¨
ä¿®å¤æ–‡æ¡£ä¸Šä¼ å’Œæ—¶åŒºé—®é¢˜
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import json
import os
from datetime import datetime
from pathlib import Path
import pytz
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# ğŸŒŸ ç›¸å¯¹è®ºå¼•æ“ - åŠ¨æ€è·¯å¾„å‘ç°ç³»ç»Ÿ
current_file = Path(__file__)
# æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½• (å‡è®¾æ­¤æ–‡ä»¶åœ¨ PROJECT_ROOT/systems/rag-system/ ä¸‹)
PROJECT_ROOT = current_file.parent.parent.parent

# é…ç½®
TIMEZONE = pytz.timezone('Asia/Shanghai')
# é”™è¯¯çš„"ç»å¯¹"è·¯å¾„: UPLOAD_FOLDER = '/workspace/systems/rag-system/uploads'
# æ­£ç¡®çš„"ç›¸å¯¹"è·¯å¾„:
UPLOAD_FOLDER = current_file.parent / 'uploads'
UPLOAD_FOLDER.mkdir(exist_ok=True)

# æ¨¡æ‹Ÿæ•°æ®å­˜å‚¨
chat_history = []
documents = []

def get_current_time():
    """è·å–å½“å‰æ—¶é—´ï¼ˆä¸­å›½æ—¶åŒºï¼‰"""
    return datetime.now(TIMEZONE)

def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200):
    """å°†æ–‡æœ¬åˆ†å—"""
    if len(text) <= chunk_size:
        return [text]
    
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        
        # å°è¯•åœ¨å¥å·ã€æ¢è¡Œç¬¦æˆ–ç©ºæ ¼å¤„åˆ†å‰²
        if end < len(text):
            for delimiter in ['\n\n', '\n', '. ', 'ã€‚', ' ']:
                last_delim = text.rfind(delimiter, start, end)
                if last_delim > start:
                    end = last_delim + len(delimiter)
                    break
        
        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)
        
        start = end - overlap
        if start >= len(text):
            break
    
    return chunks

def search_documents(query, max_results=3):
    """åœ¨æ–‡æ¡£ä¸­æœç´¢ç›¸å…³å†…å®¹"""
    if not documents:
        logger.info("æœç´¢å¤±è´¥ï¼šæ²¡æœ‰æ–‡æ¡£")
        return []
    
    logger.info(f"æœç´¢æŸ¥è¯¢: '{query}', æ–‡æ¡£æ•°é‡: {len(documents)}")
    
    # ç®€å•çš„å…³é”®è¯æœç´¢
    results = []
    query_lower = query.lower()
    
    for i, doc in enumerate(documents):
        content = doc.get('content', '')
        filename = doc.get('filename', '')
        
        logger.info(f"æ£€æŸ¥æ–‡æ¡£ {i+1}: {filename}, å†…å®¹é•¿åº¦: {len(content)}")
        
        if not content:
            logger.warning(f"æ–‡æ¡£ {filename} å†…å®¹ä¸ºç©º")
            continue
            
        content_lower = content.lower()
        
        # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼ˆç®€å•çš„å…³é”®è¯åŒ¹é…ï¼‰
        score = 0
        # ç®€å•çš„ä¸­è‹±æ–‡åˆ†è¯å¤„ç†
        import re
        # æå–ä¸­æ–‡å­—ç¬¦å’Œè‹±æ–‡å•è¯
        chinese_chars = re.findall(r'[\u4e00-\u9fff]+', query_lower)
        english_words = re.findall(r'[a-zA-Z]+', query_lower)
        
        # åˆå¹¶æ‰€æœ‰å…³é”®è¯
        all_words = []
        for chinese in chinese_chars:
            # å¯¹äºä¸­æ–‡ï¼Œæ¯ä¸ªå­—ç¬¦éƒ½ä½œä¸ºå…³é”®è¯
            all_words.extend(list(chinese))
        all_words.extend(english_words)
        
        # å»é™¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = {'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'è€Œ', 'äº†', 'å—', 'å‘¢', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å¸®', 'æˆ‘'}
        words = [word for word in all_words if word not in stop_words and len(word) >= 1]
        
        logger.info(f"å¤„ç†åçš„å…³é”®è¯: {words}")
        
        for word in words:
            logger.info(f"æœç´¢å…³é”®è¯: '{word}'")
            if word in content_lower:
                count = content_lower.count(word)
                score += count
                logger.info(f"å…³é”®è¯ '{word}' åœ¨æ–‡æ¡£ä¸­å‡ºç° {count} æ¬¡")
            else:
                logger.info(f"å…³é”®è¯ '{word}' æœªåœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°")
        
        logger.info(f"æ–‡æ¡£ {filename} ç›¸å…³æ€§åˆ†æ•°: {score}")
        
        if score > 0:
            # æå–ç›¸å…³ç‰‡æ®µ
            lines = content.split('\n')
            relevant_lines = []
            for line in lines:
                line_lower = line.lower()
                if any(word in line_lower for word in words):
                    relevant_lines.append(line.strip())
                    if len(relevant_lines) >= 5:  # æœ€å¤š5è¡Œ
                        break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³è¡Œï¼Œæå–åŒ…å«ä¸»è¦å…³é”®è¯çš„è¡Œ
            if not relevant_lines:
                main_keywords = ['nexus', 'åŠŸèƒ½', 'ç³»ç»Ÿ']
                for line in lines:
                    line_lower = line.lower()
                    if any(keyword in line_lower for keyword in main_keywords):
                        relevant_lines.append(line.strip())
                        if len(relevant_lines) >= 5:
                            break
            
            results.append({
                'filename': filename,
                'score': score,
                'content': '\n'.join(relevant_lines[:5]),
                'full_content': content
            })
    
    logger.info(f"æœç´¢ç»“æœæ•°é‡: {len(results)}")
    
    # æŒ‰ç›¸å…³æ€§æ’åº
    results.sort(key=lambda x: x['score'], reverse=True)
    return results[:max_results]

def generate_ai_response(message, current_time):
    """ç”ŸæˆAIå“åº”"""
    message_lower = message.lower()
    
    # æ—¶é—´æŸ¥è¯¢
    if 'æ—¶é—´' in message or 'ç°åœ¨' in message:
        return f'å½“å‰æ—¶é—´æ˜¯ {current_time.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")} (åŒ—äº¬æ—¶é—´)ã€‚'
    
    # ç³»ç»ŸçŠ¶æ€æŸ¥è¯¢
    elif ('ç³»ç»ŸçŠ¶æ€' in message or 'è¿è¡ŒçŠ¶æ€' in message or 'å¥åº·' in message) and not any(keyword in message_lower for keyword in ['rag', 'æ™ºèƒ½', 'åŠŸèƒ½', 'ç‰¹ç‚¹']):
        return f'NEXUSç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼èŠå¤©å†å²: {len(chat_history)} æ¡ï¼Œæ–‡æ¡£æ•°é‡: {len(documents)} ä¸ªã€‚'
    
    # æ–‡æ¡£ç›¸å…³æŸ¥è¯¢
    elif any(keyword in message_lower for keyword in ['æ€»ç»“', 'å†…å®¹', 'æ–‡æ¡£', 'ä»‹ç»', 'ä»€ä¹ˆ', 'å¦‚ä½•', 'æ€ä¹ˆ', 'åŠŸèƒ½', 'ç‰¹æ€§']):
        if not documents:
            return 'æŠ±æ­‰ï¼Œç›®å‰æ²¡æœ‰ä¸Šä¼ ä»»ä½•æ–‡æ¡£ã€‚è¯·å…ˆä¸Šä¼ æ–‡æ¡£ï¼Œç„¶åæˆ‘å°±å¯ä»¥å¸®æ‚¨åˆ†æå’Œå›ç­”ç›¸å…³é—®é¢˜äº†ã€‚'
        
        # å¦‚æœæ˜¯æ€»ç»“è¯·æ±‚ï¼Œç›´æ¥æä¾›æ–‡æ¡£æ€»ç»“
        if 'æ€»ç»“' in message_lower:
            response = "åŸºäºæ‚¨ä¸Šä¼ çš„æ–‡æ¡£ï¼Œæˆ‘ä¸ºæ‚¨æ€»ç»“å¦‚ä¸‹ï¼š\n\n"
            
            for i, doc in enumerate(documents, 1):
                content = doc.get('content', '')
                filename = doc.get('filename', '')
                
                response += f"**ğŸ“„ {filename}**\n"
                
                # æå–æ–‡æ¡£çš„å…³é”®ä¿¡æ¯
                lines = content.split('\n')
                headers = [line for line in lines if line.startswith('#') and len(line.strip()) > 1]
                
                if headers:
                    response += "ä¸»è¦ç« èŠ‚ï¼š\n"
                    for header in headers[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªæ ‡é¢˜
                        response += f"â€¢ {header.strip()}\n"
                
                # æå–æ–‡æ¡£å¼€å¤´çš„æè¿°æ€§å†…å®¹
                paragraphs = [line.strip() for line in lines if line.strip() and not line.startswith('#') and not line.startswith('-') and len(line.strip()) > 20]
                if paragraphs:
                    response += f"\næ ¸å¿ƒå†…å®¹ï¼š\n{paragraphs[0][:200]}...\n"
                
                response += f"\nğŸ“Š æ–‡æ¡£ç»Ÿè®¡ï¼š{len(content)} ä¸ªå­—ç¬¦ï¼Œ{len(lines)} è¡Œ\n\n"
            
            return response
        
        # å¯¹äºå…¶ä»–æ–‡æ¡£ç›¸å…³æŸ¥è¯¢ï¼Œæœç´¢ç›¸å…³å†…å®¹
        search_results = search_documents(message)
        
        if not search_results:
            return f'æˆ‘åœ¨å·²ä¸Šä¼ çš„ {len(documents)} ä¸ªæ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›´æ¥ç›¸å…³çš„å†…å®¹ã€‚æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ï¼Œæˆ–è€…å‘Šè¯‰æˆ‘æ‚¨æƒ³äº†è§£æ–‡æ¡£çš„å“ªä¸ªæ–¹é¢ã€‚'
        
        # ç”ŸæˆåŸºäºæ–‡æ¡£å†…å®¹çš„å›ç­”
        response = "åŸºäºæ‚¨ä¸Šä¼ çš„æ–‡æ¡£ï¼Œæˆ‘ä¸ºæ‚¨æ€»ç»“å¦‚ä¸‹ï¼š\n\n"
        
        for i, result in enumerate(search_results, 1):
            response += f"**ğŸ“„ {result['filename']}**\n"
            response += f"{result['content']}\n\n"
        
        return response
    
    # é»˜è®¤å“åº”
    else:
        if documents:
            return f'æ‚¨å¥½ï¼æˆ‘æ˜¯NEXUS AIåŠ©æ‰‹ï¼Œå·²åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£ã€‚æ‚¨å¯ä»¥è¯¢é—®æ–‡æ¡£å†…å®¹ã€è¦æ±‚æ€»ç»“ï¼Œæˆ–è€…é—®æˆ‘ä»»ä½•ç›¸å…³é—®é¢˜ã€‚å½“å‰æ—¶é—´æ˜¯ {current_time.strftime("%H:%M:%S")}ã€‚'
        else:
            return f'æ‚¨å¥½ï¼æˆ‘æ˜¯NEXUS AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼è¯·ä¸Šä¼ æ–‡æ¡£åï¼Œæˆ‘å°±å¯ä»¥å¸®æ‚¨åˆ†æå’Œå›ç­”ç›¸å…³é—®é¢˜ã€‚å½“å‰æ—¶é—´æ˜¯ {current_time.strftime("%H:%M:%S")}ã€‚'



@app.route('/api/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    current_time = get_current_time()
    
    return jsonify({
        'status': 'healthy',
        'message': 'æ™ºèƒ½RAGä»£ç†æœåŠ¡å™¨è¿è¡Œæ­£å¸¸',
        'ai_system': 'æœ¬åœ°æ™ºèƒ½å“åº”ç³»ç»Ÿ',
        'version': '1.0.0',
        'timestamp': current_time.isoformat(),
        'data': {
            'chat_history_count': len(chat_history),
            'documents_count': len(documents),
            'system_status': 'è¿è¡Œæ­£å¸¸',
            'uptime': 'ç³»ç»Ÿè¿è¡Œä¸­',
            'timezone': 'Asia/Shanghai'
        }
    })

@app.route('/api/chat', methods=['POST'])
def chat():
    """èŠå¤©ç«¯ç‚¹"""
    try:
        data = request.get_json()
        message = data.get('message', '')
        
        if not message:
            return jsonify({
                'status': 'error',
                'message': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # æ·»åŠ åˆ°èŠå¤©å†å²
        current_time = get_current_time()
        chat_entry = {
            'user_message': message,
            'timestamp': current_time.isoformat(),
            'id': len(chat_history) + 1
        }
        chat_history.append(chat_entry)
        
        # ç”ŸæˆAIå“åº”
        response = generate_ai_response(message, current_time)
        
        return jsonify({
            'success': True,
            'response': response,
            'timestamp': current_time.isoformat(),
            'status': 'success',
            'chat_id': chat_entry['id']
        })
        
    except Exception as e:
        logger.error(f"èŠå¤©å¤„ç†é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'status': 'error',
            'error': f'å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}',
            'message': f'å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}'
        }), 500

@app.route('/api/upload', methods=['POST'])
def upload():
    """æ–‡æ¡£ä¸Šä¼ ç«¯ç‚¹ - ä¿®å¤chunks_counté—®é¢˜"""
    try:
        # æ”¯æŒä¸¤ç§ä¸Šä¼ æ–¹å¼ï¼šå•æ–‡ä»¶(file)å’Œå¤šæ–‡ä»¶(files)
        files = request.files.getlist('files') or request.files.getlist('file')
        
        if not files or not files[0].filename:
            return jsonify({
                'status': 'error',
                'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'
            }), 400
        
        results = []
        current_time = get_current_time()
        
        for file in files:
            if file and file.filename:
                # ä¿å­˜æ–‡ä»¶
                filename = file.filename
                filepath = os.path.join(UPLOAD_FOLDER, filename)
                file.save(filepath)
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                try:
                    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                except Exception as e:
                    logger.error(f"è¯»å–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
                    content = ""
                
                # æ–‡æ¡£å¤„ç†
                file_size = os.path.getsize(filepath)
                chunks = chunk_text(content) if content else []
                chunks_count = len(chunks)
                
                # æ·»åŠ åˆ°æ–‡æ¡£åˆ—è¡¨
                doc_info = {
                    'filename': filename,
                    'filepath': filepath,
                    'content': content,  # æ·»åŠ æ–‡ä»¶å†…å®¹
                    'size': file_size,
                    'chunks_count': chunks_count,
                    'chunks': chunks,  # æ·»åŠ åˆ†å—å†…å®¹
                    'upload_time': current_time.isoformat(),
                    'id': len(documents) + 1
                }
                documents.append(doc_info)
                
                result = {
                    'filename': filename,
                    'status': 'success',
                    'chunks_count': chunks_count,  # ç¡®ä¿chunks_countå­˜åœ¨
                    'file_size': file_size,
                    'message': f'æ–‡æ¡£ {filename} ä¸Šä¼ æˆåŠŸï¼Œå·²åˆ†å‰²ä¸º {chunks_count} ä¸ªç‰‡æ®µ'
                }
                results.append(result)
                
                logger.info(f"æ–‡æ¡£ä¸Šä¼ æˆåŠŸ: {filename}, å¤§å°: {file_size} bytes, ç‰‡æ®µ: {chunks_count}")
        
        # æ„å»ºå“åº”
        response_data = {
            'success': True,
            'status': 'success',
            'message': f'æˆåŠŸä¸Šä¼  {len(results)} ä¸ªæ–‡ä»¶',
            'results': results,
            'timestamp': current_time.isoformat(),
            'total_documents': len(documents)
        }
        
        # ä¸ºå•æ–‡ä»¶ä¸Šä¼ æ·»åŠ documentå­—æ®µï¼ˆå‰ç«¯å…¼å®¹æ€§ï¼‰
        if len(results) == 1:
            response_data['document'] = results[0]
        
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"æ–‡æ¡£ä¸Šä¼ é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'status': 'error',
            'error': f'ä¸Šä¼ å¤±è´¥: {str(e)}',
            'message': f'ä¸Šä¼ å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/clear', methods=['POST'])
def clear_chat():
    """æ¸…é™¤èŠå¤©å†å²"""
    global chat_history
    chat_history = []
    
    current_time = get_current_time()
    return jsonify({
        'success': True,
        'status': 'success',
        'message': 'èŠå¤©å†å²å·²æ¸…é™¤',
        'timestamp': current_time.isoformat()
    })

@app.route('/api/documents', methods=['GET'])
def get_documents():
    """è·å–æ–‡æ¡£åˆ—è¡¨"""
    current_time = get_current_time()
    
    return jsonify({
        'status': 'success',
        'documents': documents,
        'count': len(documents),
        'timestamp': current_time.isoformat()
    })

@app.route('/api/chat/history', methods=['GET'])
def get_chat_history():
    """è·å–èŠå¤©å†å²"""
    current_time = get_current_time()
    
    return jsonify({
        'status': 'success',
        'chat_history': chat_history,
        'count': len(chat_history),
        'timestamp': current_time.isoformat()
    })

@app.route('/', methods=['GET'])
def index():
    """æ ¹è·¯å¾„"""
    current_time = get_current_time()
    
    return jsonify({
        'service': 'NEXUS RAG System',
        'status': 'running',
        'version': '1.0.0',
        'timestamp': current_time.isoformat(),
        'endpoints': [
            '/api/health',
            '/api/chat',
            '/api/upload',
            '/api/clear',
            '/api/documents',
            '/api/chat/history'
        ]
    })

if __name__ == '__main__':
    # ğŸŒŸ åŠ¨æ€ç«¯å£é…ç½® - ä»ç¯å¢ƒå˜é‡è·å–ç«¯å£ï¼Œæ”¯æŒæœåŠ¡å‘ç°ç³»ç»Ÿ
    port = int(os.environ.get('PORT', 8502))
    
    print("ğŸš€ å¯åŠ¨NEXUS RAGç³»ç»ŸæœåŠ¡å™¨...")
    print(f"ğŸ“ ä¸Šä¼ ç›®å½•: {UPLOAD_FOLDER}")
    print(f"ğŸ• æ—¶åŒº: {TIMEZONE}")
    print(f"ğŸŒ æœåŠ¡å™¨åœ°å€: http://0.0.0.0:{port}")
    print(f"ğŸ“¡ å¥åº·æ£€æŸ¥: http://localhost:{port}/api/health")
    print(f"ğŸ’¬ èŠå¤©æ¥å£: http://localhost:{port}/api/chat")
    print(f"ğŸ“¤ ä¸Šä¼ æ¥å£: http://localhost:{port}/api/upload")
    
    app.run(
        host='0.0.0.0',
        port=port,
        debug=False,
        threaded=True
    )