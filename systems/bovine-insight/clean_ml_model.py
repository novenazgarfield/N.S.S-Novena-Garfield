#!/usr/bin/env python3
"""
æ¸…ç†æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œé‡ç½®ä¸ºå¹²å‡€çŠ¶æ€
"""

import os
import pickle
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler

def create_clean_model():
    """åˆ›å»ºå¹²å‡€çš„æœºå™¨å­¦ä¹ æ¨¡å‹"""
    
    # åˆ›å»ºå¹²å‡€çš„éšæœºæ£®æ—æ¨¡å‹
    model = RandomForestRegressor(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    )
    
    # åˆ›å»ºæ ‡å‡†åŒ–å™¨
    scaler = StandardScaler()
    
    # ä½¿ç”¨åŸºç¡€çš„ç‰¹å¾æ•°æ®è¿›è¡Œåˆå§‹åŒ–è®­ç»ƒ
    # è¿™äº›æ˜¯æ ‡å‡†çš„ç‰›åªä½“å†µè¯„åˆ†ç‰¹å¾
    base_features = np.array([
        [0.5, 0.6, 0.7, 0.8, 0.9],  # æ ‡å‡†ä½“å‹ç‰¹å¾
        [0.6, 0.7, 0.8, 0.9, 1.0],  # å¥åº·ä½“å‹ç‰¹å¾
        [0.4, 0.5, 0.6, 0.7, 0.8],  # åç˜¦ä½“å‹ç‰¹å¾
        [0.7, 0.8, 0.9, 1.0, 1.1],  # åèƒ–ä½“å‹ç‰¹å¾
    ])
    
    base_scores = np.array([3.0, 3.5, 2.5, 4.0])  # å¯¹åº”çš„BCSè¯„åˆ†
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler.fit(base_features)
    scaled_features = scaler.transform(base_features)
    
    # è®­ç»ƒæ¨¡å‹
    model.fit(scaled_features, base_scores)
    
    return model, scaler

def save_clean_model():
    """ä¿å­˜å¹²å‡€çš„æ¨¡å‹"""
    
    # ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨
    os.makedirs('models', exist_ok=True)
    
    # åˆ›å»ºå¹²å‡€çš„æ¨¡å‹
    model, scaler = create_clean_model()
    
    # ä¿å­˜æ¨¡å‹
    with open('models/bcs_predictor_clean.pkl', 'wb') as f:
        pickle.dump(model, f)
    
    # ä¿å­˜æ ‡å‡†åŒ–å™¨
    with open('models/bcs_predictor_clean_scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    
    print("âœ… å¹²å‡€çš„æœºå™¨å­¦ä¹ æ¨¡å‹å·²åˆ›å»ºå¹¶ä¿å­˜")
    print("ğŸ“ æ¨¡å‹æ–‡ä»¶: models/bcs_predictor_clean.pkl")
    print("ğŸ“ æ ‡å‡†åŒ–å™¨: models/bcs_predictor_clean_scaler.pkl")

if __name__ == "__main__":
    save_clean_model()