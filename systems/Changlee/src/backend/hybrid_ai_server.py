#!/usr/bin/env python3
"""
Changleeæ··åˆAIæœåŠ¡å™¨
åŸºäºFastAPIçš„é«˜æ€§èƒ½å¼‚æ­¥AIæœåŠ¡
æ”¯æŒæœ¬åœ°AI (Gemma 2) + äº‘ç«¯API (Geminiç­‰) çš„æ··åˆæ™ºèƒ½å¯¹è¯
"""

import os
import sys
import asyncio
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import argparse
from contextlib import asynccontextmanager

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from services.HybridAIService import HybridAIService, AIServiceType
    HYBRID_AI_AVAILABLE = True
except ImportError:
    # å›é€€åˆ°åŸå§‹çš„LocalAIService
    try:
        from services.LocalAIService import LocalAIService
        HybridAIService = LocalAIService
        AIServiceType = None
        HYBRID_AI_AVAILABLE = False
        print("âš ï¸ ä½¿ç”¨åŸå§‹LocalAIServiceï¼Œæ··åˆAIåŠŸèƒ½ä¸å¯ç”¨")
    except ImportError as e:
        print(f"âŒ å¯¼å…¥AIæœåŠ¡å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿AIæœåŠ¡æ–‡ä»¶å­˜åœ¨ä¸”ä¾èµ–å·²å®‰è£…")
        sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€AIæœåŠ¡å®ä¾‹
ai_service: Optional[HybridAIService] = None

# Pydanticæ¨¡å‹
class GenerateRequest(BaseModel):
    """AIç”Ÿæˆè¯·æ±‚æ¨¡å‹"""
    prompt: str = Field(..., description="ç”¨æˆ·è¾“å…¥æç¤º")
    context: str = Field(default="daily_greeting", description="å¯¹è¯ä¸Šä¸‹æ–‡")
    service_type: Optional[str] = Field(default=None, description="æŒ‡å®šAIæœåŠ¡ç±»å‹")
    max_length: int = Field(default=256, description="æœ€å¤§ç”Ÿæˆé•¿åº¦")
    temperature: float = Field(default=0.7, description="ç”Ÿæˆæ¸©åº¦")

class WordHintRequest(BaseModel):
    """å•è¯æç¤ºè¯·æ±‚æ¨¡å‹"""
    word: str = Field(..., description="éœ€è¦æç¤ºçš„å•è¯")
    difficulty: str = Field(default="medium", description="éš¾åº¦çº§åˆ«")

class GreetingRequest(BaseModel):
    """é—®å€™è¯·æ±‚æ¨¡å‹"""
    time_of_day: str = Field(default="morning", description="æ—¶é—´æ®µ")
    user_name: Optional[str] = Field(default=None, description="ç”¨æˆ·åç§°")

class ExplanationRequest(BaseModel):
    """è§£é‡Šè¯·æ±‚æ¨¡å‹"""
    concept: str = Field(..., description="éœ€è¦è§£é‡Šçš„æ¦‚å¿µ")
    level: str = Field(default="beginner", description="è§£é‡Šçº§åˆ«")

class ServiceSwitchRequest(BaseModel):
    """æœåŠ¡åˆ‡æ¢è¯·æ±‚æ¨¡å‹"""
    service_type: str = Field(..., description="ç›®æ ‡æœåŠ¡ç±»å‹")

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global ai_service
    
    # å¯åŠ¨æ—¶åˆå§‹åŒ–AIæœåŠ¡
    logger.info("ğŸš€ å¯åŠ¨Changleeæ··åˆAIæœåŠ¡å™¨...")
    
    try:
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        preferred_service = os.getenv('PREFERRED_AI_SERVICE', 'auto').lower()
        local_model = os.getenv('LOCAL_MODEL_NAME', 'google/gemma-2-2b')
        max_memory = float(os.getenv('MAX_MEMORY_GB', '4.0'))
        
        # è§£æé¦–é€‰æœåŠ¡ç±»å‹
        if HYBRID_AI_AVAILABLE:
            service_type_map = {
                'local': AIServiceType.LOCAL,
                'gemini': AIServiceType.GEMINI,
                'deepseek': AIServiceType.DEEPSEEK,
                'auto': AIServiceType.AUTO
            }
            preferred_type = service_type_map.get(preferred_service, AIServiceType.AUTO)
        else:
            preferred_type = None
        
        # åˆå§‹åŒ–AIæœåŠ¡
        if HYBRID_AI_AVAILABLE:
            ai_service = HybridAIService(
                preferred_service=preferred_type,
                local_model_name=local_model,
                max_memory_gb=max_memory
            )
        else:
            ai_service = LocalAIService(
                model_name=local_model,
                max_memory_gb=max_memory
            )
        
        logger.info("âœ… AIæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        ai_service = None
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†èµ„æº
    logger.info("ğŸ›‘ å…³é—­Changleeæ··åˆAIæœåŠ¡å™¨...")
    if ai_service:
        try:
            if hasattr(ai_service, 'optimize_memory'):
                ai_service.optimize_memory()
        except Exception as e:
            logger.error(f"âŒ èµ„æºæ¸…ç†å¤±è´¥: {e}")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Changleeæ··åˆAIæœåŠ¡",
    description="æ”¯æŒæœ¬åœ°AIå’Œäº‘ç«¯APIçš„æ··åˆæ™ºèƒ½å¯¹è¯æœåŠ¡",
    version="2.0.0",
    lifespan=lifespan
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "Changleeæ··åˆAIæœåŠ¡",
        "version": "2.0.0",
        "status": "running",
        "hybrid_ai": HYBRID_AI_AVAILABLE,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        if hasattr(ai_service, 'health_check'):
            status = await ai_service.health_check()
        else:
            status = {
                "healthy": True,
                "service": "local_only",
                "timestamp": datetime.now().isoformat()
            }
        
        return JSONResponse(
            status_code=200 if status.get("healthy", True) else 503,
            content=status
        )
    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=503, detail=f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")

@app.get("/status")
async def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        if hasattr(ai_service, 'get_service_status'):
            status = ai_service.get_service_status()
        else:
            status = {
                "service_name": "Changleeæœ¬åœ°AIæœåŠ¡",
                "version": "1.0.0",
                "model_loaded": hasattr(ai_service, 'model') and ai_service.model is not None,
                "timestamp": datetime.now().isoformat()
            }
        
        return {"success": True, "data": status}
    except Exception as e:
        logger.error(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}")

@app.post("/generate")
async def generate_response(request: GenerateRequest):
    """é€šç”¨AIç”Ÿæˆæ¥å£"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        # è§£ææœåŠ¡ç±»å‹
        service_type = None
        if HYBRID_AI_AVAILABLE and request.service_type:
            service_type_map = {
                'local': AIServiceType.LOCAL,
                'gemini': AIServiceType.GEMINI,
                'deepseek': AIServiceType.DEEPSEEK
            }
            service_type = service_type_map.get(request.service_type.lower())
        
        # ç”Ÿæˆå›å¤
        if hasattr(ai_service, 'generate'):
            result = await ai_service.generate(
                prompt=request.prompt,
                context=request.context,
                service_type=service_type
            )
        else:
            # å›é€€åˆ°åŸå§‹æ–¹æ³•
            result = await ai_service.generate_response(
                prompt=request.prompt,
                context=request.context,
                max_length=request.max_length,
                temperature=request.temperature
            )
        
        if result.get("success", True):
            return {
                "success": True,
                "response": result.get("response", result.get("text", "")),
                "metadata": {
                    "service": result.get("service", "unknown"),
                    "model": result.get("model", "unknown"),
                    "generation_time": result.get("generation_time", 0),
                    "context": request.context,
                    "fallback": result.get("fallback", False)
                }
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "ç”Ÿæˆå¤±è´¥"))
            
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå›å¤å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå›å¤å¤±è´¥: {str(e)}")

@app.post("/word_hint")
async def get_word_hint(request: WordHintRequest):
    """è·å–å•è¯å­¦ä¹ æç¤º"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        prompt = f"è¯·ä¸ºå•è¯ '{request.word}' æä¾›å­¦ä¹ æç¤ºï¼ŒåŒ…æ‹¬è¯æ ¹ã€è®°å¿†æ–¹æ³•ã€ä¾‹å¥ç­‰ã€‚éš¾åº¦çº§åˆ«ï¼š{request.difficulty}"
        
        if hasattr(ai_service, 'generate'):
            result = await ai_service.generate(prompt, "word_learning")
        else:
            result = await ai_service.generate_response(prompt, "word_learning")
        
        if result.get("success", True):
            return {
                "success": True,
                "word": request.word,
                "hint": result.get("response", result.get("text", "")),
                "difficulty": request.difficulty
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "ç”Ÿæˆæç¤ºå¤±è´¥"))
            
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå•è¯æç¤ºå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå•è¯æç¤ºå¤±è´¥: {str(e)}")

@app.post("/encouragement")
async def get_encouragement():
    """è·å–å­¦ä¹ é¼“åŠ±è¯­"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        prompt = "ç”¨æˆ·åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­é‡åˆ°å›°éš¾ï¼Œéœ€è¦é¼“åŠ±å’Œæ”¯æŒã€‚"
        
        if hasattr(ai_service, 'generate'):
            result = await ai_service.generate(prompt, "encouragement")
        else:
            result = await ai_service.generate_response(prompt, "encouragement")
        
        if result.get("success", True):
            return {
                "success": True,
                "encouragement": result.get("response", result.get("text", "")),
                "timestamp": datetime.now().isoformat()
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "ç”Ÿæˆé¼“åŠ±è¯­å¤±è´¥"))
            
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆé¼“åŠ±è¯­å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆé¼“åŠ±è¯­å¤±è´¥: {str(e)}")

@app.post("/greeting")
async def get_greeting(request: GreetingRequest):
    """è·å–ä¸ªæ€§åŒ–é—®å€™è¯­"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        user_part = f"ï¼Œ{request.user_name}" if request.user_name else ""
        prompt = f"ç°åœ¨æ˜¯{request.time_of_day}æ—¶æ®µ{user_part}ï¼Œè¯·ç»™å‡ºä¸€å¥æ¸©æš–çš„é—®å€™ã€‚"
        
        if hasattr(ai_service, 'generate'):
            result = await ai_service.generate(prompt, "daily_greeting")
        else:
            result = await ai_service.generate_response(prompt, "daily_greeting")
        
        if result.get("success", True):
            return {
                "success": True,
                "greeting": result.get("response", result.get("text", "")),
                "time_of_day": request.time_of_day,
                "user_name": request.user_name
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "ç”Ÿæˆé—®å€™è¯­å¤±è´¥"))
            
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆé—®å€™è¯­å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆé—®å€™è¯­å¤±è´¥: {str(e)}")

@app.post("/explanation")
async def get_explanation(request: ExplanationRequest):
    """è·å–æ¦‚å¿µè§£é‡Š"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        prompt = f"è¯·è§£é‡Šæ¦‚å¿µ '{request.concept}'ï¼Œè§£é‡Šçº§åˆ«ï¼š{request.level}ã€‚è¯·ç”¨ç®€å•æ˜“æ‡‚çš„æ–¹å¼ï¼Œå¯ä»¥ä½¿ç”¨æ¯”å–»å’Œä¾‹å­ã€‚"
        
        if hasattr(ai_service, 'generate'):
            result = await ai_service.generate(prompt, "explanation")
        else:
            result = await ai_service.generate_response(prompt, "explanation")
        
        if result.get("success", True):
            return {
                "success": True,
                "concept": request.concept,
                "explanation": result.get("response", result.get("text", "")),
                "level": request.level
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "ç”Ÿæˆè§£é‡Šå¤±è´¥"))
            
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆè§£é‡Šå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆè§£é‡Šå¤±è´¥: {str(e)}")

@app.get("/services")
async def list_services():
    """åˆ—å‡ºå¯ç”¨çš„AIæœåŠ¡"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        if hasattr(ai_service, 'available_services'):
            services = [s.value for s in ai_service.available_services]
            current = ai_service.current_service.value if ai_service.current_service else None
        else:
            services = ["local"]
            current = "local"
        
        return {
            "success": True,
            "available_services": services,
            "current_service": current,
            "hybrid_ai_enabled": HYBRID_AI_AVAILABLE
        }
    except Exception as e:
        logger.error(f"âŒ è·å–æœåŠ¡åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æœåŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")

@app.post("/switch_service")
async def switch_service(request: ServiceSwitchRequest):
    """åˆ‡æ¢AIæœåŠ¡"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    if not HYBRID_AI_AVAILABLE:
        raise HTTPException(status_code=400, detail="æ··åˆAIåŠŸèƒ½ä¸å¯ç”¨")
    
    try:
        service_type_map = {
            'local': AIServiceType.LOCAL,
            'gemini': AIServiceType.GEMINI,
            'deepseek': AIServiceType.DEEPSEEK,
            'auto': AIServiceType.AUTO
        }
        
        target_service = service_type_map.get(request.service_type.lower())
        if not target_service:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æœåŠ¡ç±»å‹: {request.service_type}")
        
        success = ai_service.switch_service(target_service)
        
        return {
            "success": success,
            "current_service": ai_service.current_service.value if success else None,
            "message": f"å·²åˆ‡æ¢åˆ° {request.service_type} æœåŠ¡" if success else "åˆ‡æ¢å¤±è´¥"
        }
        
    except Exception as e:
        logger.error(f"âŒ åˆ‡æ¢æœåŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ‡æ¢æœåŠ¡å¤±è´¥: {str(e)}")

@app.post("/cache/clear")
async def clear_cache(background_tasks: BackgroundTasks):
    """æ¸…ç†ç¼“å­˜"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        if hasattr(ai_service, 'clear_cache'):
            background_tasks.add_task(ai_service.clear_cache)
        
        return {
            "success": True,
            "message": "ç¼“å­˜æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}")

@app.post("/memory/optimize")
async def optimize_memory(background_tasks: BackgroundTasks):
    """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    if not ai_service:
        raise HTTPException(status_code=503, detail="AIæœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        if hasattr(ai_service, 'optimize_memory'):
            background_tasks.add_task(ai_service.optimize_memory)
        
        return {
            "success": True,
            "message": "å†…å­˜ä¼˜åŒ–ä»»åŠ¡å·²å¯åŠ¨",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"âŒ å†…å­˜ä¼˜åŒ–å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å†…å­˜ä¼˜åŒ–å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Changleeæ··åˆAIæœåŠ¡å™¨")
    parser.add_argument("--host", default="0.0.0.0", help="æœåŠ¡å™¨ä¸»æœºåœ°å€")
    parser.add_argument("--port", type=int, default=8001, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--workers", type=int, default=1, help="å·¥ä½œè¿›ç¨‹æ•°")
    parser.add_argument("--reload", action="store_true", help="å¯ç”¨è‡ªåŠ¨é‡è½½")
    parser.add_argument("--log-level", default="info", help="æ—¥å¿—çº§åˆ«")
    
    args = parser.parse_args()
    
    logger.info(f"ğŸš€ å¯åŠ¨Changleeæ··åˆAIæœåŠ¡å™¨...")
    logger.info(f"   åœ°å€: http://{args.host}:{args.port}")
    logger.info(f"   æ··åˆAI: {'å¯ç”¨' if HYBRID_AI_AVAILABLE else 'ç¦ç”¨'}")
    
    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        "hybrid_ai_server:app",
        host=args.host,
        port=args.port,
        workers=args.workers,
        reload=args.reload,
        log_level=args.log_level,
        access_log=True
    )

if __name__ == "__main__":
    main()