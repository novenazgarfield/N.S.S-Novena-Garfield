#!/usr/bin/env python3
"""
ğŸ“‹ Managementé¡¹ç›®ç®¡ç†ç³»ç»Ÿè‡ªåŠ¨åŒ–ä¼˜åŒ–å™¨
==================================

ä¼˜åŒ–Managementç³»ç»Ÿçš„è‡ªåŠ¨åŒ–ç¨‹åº¦å’Œè¿ç»´æ•ˆç‡
- æ•´åˆé‡å¤è„šæœ¬åŠŸèƒ½
- æ·»åŠ è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹
- å®Œå–„ç³»ç»Ÿç›‘æ§
- ç»Ÿä¸€æ—¥å¿—ç®¡ç†
- æ·»åŠ å¥åº·æ£€æŸ¥æœºåˆ¶

ä¿æŒæ‰€æœ‰åŸæœ‰åŠŸèƒ½ä¸å˜
"""

import os
import json
import shutil
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
from datetime import datetime, timedelta
import re
import yaml
import logging

class ManagementOptimizer:
    """Managementç³»ç»Ÿä¼˜åŒ–å™¨"""
    
    def __init__(self, management_dir: Path = None):
        self.management_dir = management_dir or Path(__file__).parent
        self.scripts_dir = self.management_dir / "scripts"
        self.logs_dir = self.management_dir / "logs"
        self.config_dir = self.management_dir / "config"
        
        self.optimization_log = []
        self.script_analysis = {}
        self.automation_metrics = {}
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.logs_dir.mkdir(exist_ok=True)
        self.config_dir.mkdir(exist_ok=True)
    
    def log_action(self, action: str, details: str = "", level: str = "INFO"):
        """è®°å½•ä¼˜åŒ–æ“ä½œ"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "details": details,
            "level": level
        }
        self.optimization_log.append(log_entry)
        
        emoji = "âœ…" if level == "INFO" else "âš ï¸" if level == "WARN" else "âŒ"
        print(f"{emoji} {action}: {details}")
    
    def analyze_script_redundancy(self) -> Dict[str, Any]:
        """åˆ†æè„šæœ¬å†—ä½™"""
        self.log_action("å¼€å§‹è„šæœ¬å†—ä½™åˆ†æ", "æ‰«ææ‰€æœ‰ç®¡ç†è„šæœ¬")
        
        if not self.scripts_dir.exists():
            self.log_action("è„šæœ¬ç›®å½•ä¸å­˜åœ¨", str(self.scripts_dir), "WARN")
            return {}
        
        # æ”¶é›†æ‰€æœ‰è„šæœ¬æ–‡ä»¶
        script_files = []
        for pattern in ["*.py", "*.sh", "*.js", "*.bat"]:
            script_files.extend(self.scripts_dir.glob(f"**/{pattern}"))
        
        # åˆ†æè„šæœ¬åŠŸèƒ½
        script_functions = {}
        duplicate_groups = {}
        
        for script_file in script_files:
            analysis = self._analyze_script_file(script_file)
            script_functions[script_file.name] = analysis
            
            # æŒ‰åŠŸèƒ½åˆ†ç»„
            function_type = analysis.get("function_type", "unknown")
            if function_type not in duplicate_groups:
                duplicate_groups[function_type] = []
            duplicate_groups[function_type].append(script_file.name)
        
        # æ‰¾å‡ºé‡å¤åŠŸèƒ½
        redundant_groups = {k: v for k, v in duplicate_groups.items() if len(v) > 1}
        
        analysis_result = {
            "total_scripts": len(script_files),
            "script_functions": script_functions,
            "duplicate_groups": duplicate_groups,
            "redundant_groups": redundant_groups,
            "redundancy_percentage": len(redundant_groups) / len(duplicate_groups) * 100 if duplicate_groups else 0
        }
        
        self.script_analysis = analysis_result
        
        self.log_action(
            "è„šæœ¬å†—ä½™åˆ†æå®Œæˆ",
            f"æ€»è„šæœ¬: {len(script_files)}, å†—ä½™ç»„: {len(redundant_groups)}, "
            f"å†—ä½™ç‡: {analysis_result['redundancy_percentage']:.1f}%"
        )
        
        return analysis_result
    
    def _analyze_script_file(self, script_file: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªè„šæœ¬æ–‡ä»¶"""
        try:
            content = script_file.read_text(encoding='utf-8')
            
            # ç¡®å®šè„šæœ¬åŠŸèƒ½ç±»å‹
            function_type = self._determine_function_type(script_file.name, content)
            
            # åˆ†æè„šæœ¬å¤æ‚åº¦
            lines = content.splitlines()
            code_lines = [line for line in lines if line.strip() and not line.strip().startswith('#')]
            
            # åˆ†æä¾èµ–
            dependencies = self._extract_dependencies(content, script_file.suffix)
            
            # åˆ†æå‚æ•°
            parameters = self._extract_parameters(content, script_file.suffix)
            
            return {
                "function_type": function_type,
                "size": len(content),
                "lines": len(lines),
                "code_lines": len(code_lines),
                "dependencies": dependencies,
                "parameters": parameters,
                "last_modified": datetime.fromtimestamp(script_file.stat().st_mtime).isoformat()
            }
            
        except Exception as e:
            return {"error": str(e)}
    
    def _determine_function_type(self, filename: str, content: str) -> str:
        """ç¡®å®šè„šæœ¬åŠŸèƒ½ç±»å‹"""
        filename_lower = filename.lower()
        content_lower = content.lower()
        
        if any(keyword in filename_lower for keyword in ["start", "launch", "run"]):
            return "startup"
        elif any(keyword in filename_lower for keyword in ["deploy", "deployment"]):
            return "deployment"
        elif any(keyword in filename_lower for keyword in ["monitor", "check", "health"]):
            return "monitoring"
        elif any(keyword in filename_lower for keyword in ["backup", "archive"]):
            return "backup"
        elif any(keyword in filename_lower for keyword in ["clean", "cleanup"]):
            return "cleanup"
        elif any(keyword in filename_lower for keyword in ["test", "testing"]):
            return "testing"
        elif any(keyword in content_lower for keyword in ["docker", "container"]):
            return "containerization"
        elif any(keyword in content_lower for keyword in ["git", "commit", "push"]):
            return "version_control"
        else:
            return "utility"
    
    def _extract_dependencies(self, content: str, file_ext: str) -> List[str]:
        """æå–è„šæœ¬ä¾èµ–"""
        dependencies = []
        
        if file_ext == ".py":
            # Python imports
            imports = re.findall(r'(?:from\s+(\S+)\s+import|import\s+(\S+))', content)
            dependencies.extend([imp[0] or imp[1] for imp in imports])
        elif file_ext == ".sh":
            # Shell commands
            commands = re.findall(r'(?:^|\s)([a-zA-Z][a-zA-Z0-9_-]*)\s', content)
            dependencies.extend(list(set(commands[:10])))  # é™åˆ¶æ•°é‡
        elif file_ext == ".js":
            # JavaScript requires/imports
            requires = re.findall(r'require\([\'"]([^\'"]+)[\'"]\)', content)
            imports = re.findall(r'import.*from\s+[\'"]([^\'"]+)[\'"]', content)
            dependencies.extend(requires + imports)
        
        return list(set(dependencies[:10]))  # å»é‡å¹¶é™åˆ¶æ•°é‡
    
    def _extract_parameters(self, content: str, file_ext: str) -> List[str]:
        """æå–è„šæœ¬å‚æ•°"""
        parameters = []
        
        if file_ext == ".py":
            # Python argparse
            args = re.findall(r'add_argument\([\'"]([^\'"]+)[\'"]', content)
            parameters.extend(args)
        elif file_ext == ".sh":
            # Shell parameters
            params = re.findall(r'\$\{?(\w+)\}?', content)
            parameters.extend(list(set(params)))
        
        return list(set(parameters[:10]))  # å»é‡å¹¶é™åˆ¶æ•°é‡
    
    def create_unified_script_manager(self):
        """åˆ›å»ºç»Ÿä¸€è„šæœ¬ç®¡ç†å™¨"""
        self.log_action("åˆ›å»ºç»Ÿä¸€è„šæœ¬ç®¡ç†å™¨", "æ•´åˆæ‰€æœ‰ç®¡ç†è„šæœ¬åŠŸèƒ½")
        
        unified_manager = '''#!/usr/bin/env python3
"""
ğŸ“‹ ç»Ÿä¸€è„šæœ¬ç®¡ç†å™¨
================

æ•´åˆæ‰€æœ‰Managementè„šæœ¬åŠŸèƒ½ï¼Œæä¾›ç»Ÿä¸€çš„ç®¡ç†æ¥å£
- å¯åŠ¨è„šæœ¬ç»Ÿä¸€ç®¡ç†
- éƒ¨ç½²æµç¨‹è‡ªåŠ¨åŒ–
- ç›‘æ§å’Œå¥åº·æ£€æŸ¥
- æ—¥å¿—ç»Ÿä¸€ç®¡ç†

è‡ªåŠ¨ç”Ÿæˆäº: {timestamp}
"""

import os
import sys
import json
import subprocess
import threading
import time
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import argparse

class UnifiedScriptManager:
    """ç»Ÿä¸€è„šæœ¬ç®¡ç†å™¨"""
    
    def __init__(self):
        self.management_dir = Path(__file__).parent
        self.scripts_dir = self.management_dir / "scripts"
        self.logs_dir = self.management_dir / "logs"
        self.config_dir = self.management_dir / "config"
        
        # è„šæœ¬åˆ†ç±»
        self.script_categories = {{script_categories}}
        
        # è¿è¡ŒçŠ¶æ€
        self.running_processes = {{}}
        self.process_logs = {{}}
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        self.logs_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.logs_dir / 'unified_manager.log'),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger('UnifiedScriptManager')
    
    def list_scripts(self, category: Optional[str] = None) -> Dict[str, List[str]]:
        """åˆ—å‡ºæ‰€æœ‰è„šæœ¬"""
        if category:
            return {{category: self.script_categories.get(category, [])}}
        return self.script_categories
    
    def run_script(self, script_name: str, args: List[str] = None) -> bool:
        """è¿è¡ŒæŒ‡å®šè„šæœ¬"""
        script_path = self._find_script(script_name)
        if not script_path:
            self.logger.error(f"Script not found: {{script_name}}")
            return False
        
        try:
            cmd = [sys.executable if script_path.suffix == '.py' else 'bash', str(script_path)]
            if args:
                cmd.extend(args)
            
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=script_path.parent
            )
            
            self.running_processes[script_name] = process
            self.logger.info(f"Started script: {{script_name}} (PID: {{process.pid}})")
            
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to run script {{script_name}}: {{e}}")
            return False
    
    def stop_script(self, script_name: str) -> bool:
        """åœæ­¢æŒ‡å®šè„šæœ¬"""
        if script_name not in self.running_processes:
            self.logger.warning(f"Script not running: {{script_name}}")
            return False
        
        try:
            process = self.running_processes[script_name]
            process.terminate()
            process.wait(timeout=10)
            
            del self.running_processes[script_name]
            self.logger.info(f"Stopped script: {{script_name}}")
            
            return True
            
        except subprocess.TimeoutExpired:
            process.kill()
            del self.running_processes[script_name]
            self.logger.warning(f"Force killed script: {{script_name}}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to stop script {{script_name}}: {{e}}")
            return False
    
    def get_script_status(self) -> Dict[str, str]:
        """è·å–è„šæœ¬è¿è¡ŒçŠ¶æ€"""
        status = {{}}
        
        for script_name, process in self.running_processes.items():
            if process.poll() is None:
                status[script_name] = "running"
            else:
                status[script_name] = "stopped"
                # æ¸…ç†å·²åœæ­¢çš„è¿›ç¨‹
                del self.running_processes[script_name]
        
        return status
    
    def _find_script(self, script_name: str) -> Optional[Path]:
        """æŸ¥æ‰¾è„šæœ¬æ–‡ä»¶"""
        for category, scripts in self.script_categories.items():
            if script_name in scripts:
                # å°è¯•ä¸åŒçš„æ‰©å±•å
                for ext in ['.py', '.sh', '.js']:
                    script_path = self.scripts_dir / f"{{script_name}}{{ext}}"
                    if script_path.exists():
                        return script_path
                
                # åœ¨å­ç›®å½•ä¸­æŸ¥æ‰¾
                for script_file in self.scripts_dir.glob(f"**/{{script_name}}.*"):
                    return script_file
        
        return None
    
    def health_check(self) -> Dict[str, Any]:
        """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        health_status = {{
            "timestamp": datetime.now().isoformat(),
            "overall_status": "healthy",
            "checks": {{}}
        }}
        
        # æ£€æŸ¥è„šæœ¬ç›®å½•
        health_status["checks"]["scripts_directory"] = {{
            "status": "ok" if self.scripts_dir.exists() else "error",
            "path": str(self.scripts_dir)
        }}
        
        # æ£€æŸ¥æ—¥å¿—ç›®å½•
        health_status["checks"]["logs_directory"] = {{
            "status": "ok" if self.logs_dir.exists() else "error",
            "path": str(self.logs_dir)
        }}
        
        # æ£€æŸ¥è¿è¡Œä¸­çš„è¿›ç¨‹
        health_status["checks"]["running_processes"] = {{
            "status": "ok",
            "count": len(self.running_processes),
            "processes": list(self.running_processes.keys())
        }}
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        try:
            disk_usage = shutil.disk_usage(self.management_dir)
            free_gb = disk_usage.free / (1024**3)
            
            health_status["checks"]["disk_space"] = {{
                "status": "ok" if free_gb > 1 else "warning",
                "free_gb": round(free_gb, 2)
            }}
        except Exception as e:
            health_status["checks"]["disk_space"] = {{
                "status": "error",
                "error": str(e)
            }}
        
        # ç¡®å®šæ€»ä½“çŠ¶æ€
        error_checks = [check for check in health_status["checks"].values() if check["status"] == "error"]
        if error_checks:
            health_status["overall_status"] = "error"
        elif any(check["status"] == "warning" for check in health_status["checks"].values()):
            health_status["overall_status"] = "warning"
        
        return health_status
    
    def interactive_menu(self):
        """äº¤äº’å¼èœå•"""
        while True:
            print("\\n" + "=" * 60)
            print("ğŸ“‹ ç»Ÿä¸€è„šæœ¬ç®¡ç†å™¨")
            print("=" * 60)
            print("1. åˆ—å‡ºæ‰€æœ‰è„šæœ¬")
            print("2. è¿è¡Œè„šæœ¬")
            print("3. åœæ­¢è„šæœ¬")
            print("4. æŸ¥çœ‹è„šæœ¬çŠ¶æ€")
            print("5. ç³»ç»Ÿå¥åº·æ£€æŸ¥")
            print("0. é€€å‡º")
            print("-" * 60)
            
            try:
                choice = input("è¯·é€‰æ‹©æ“ä½œ (0-5): ").strip()
                
                if choice == "0":
                    # åœæ­¢æ‰€æœ‰è¿è¡Œä¸­çš„è„šæœ¬
                    for script_name in list(self.running_processes.keys()):
                        self.stop_script(script_name)
                    print("ğŸ‘‹ å†è§!")
                    break
                    
                elif choice == "1":
                    self._show_scripts()
                    
                elif choice == "2":
                    self._interactive_run_script()
                    
                elif choice == "3":
                    self._interactive_stop_script()
                    
                elif choice == "4":
                    self._show_script_status()
                    
                elif choice == "5":
                    self._show_health_check()
                    
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
                    
            except KeyboardInterrupt:
                print("\\n\\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                print(f"âŒ æ“ä½œå¤±è´¥: {{e}}")
    
    def _show_scripts(self):
        """æ˜¾ç¤ºæ‰€æœ‰è„šæœ¬"""
        print("\\nğŸ“œ å¯ç”¨è„šæœ¬:")
        for category, scripts in self.script_categories.items():
            print(f"\\n{category.upper()}:")
            for script in scripts:
                print(f"  - {{script}}")
    
    def _interactive_run_script(self):
        """äº¤äº’å¼è¿è¡Œè„šæœ¬"""
        script_name = input("è¯·è¾“å…¥è„šæœ¬åç§°: ").strip()
        if script_name:
            args_input = input("è¯·è¾“å…¥å‚æ•° (å¯é€‰): ").strip()
            args = args_input.split() if args_input else []
            
            if self.run_script(script_name, args):
                print(f"âœ… è„šæœ¬ {{script_name}} å·²å¯åŠ¨")
            else:
                print(f"âŒ è„šæœ¬ {{script_name}} å¯åŠ¨å¤±è´¥")
    
    def _interactive_stop_script(self):
        """äº¤äº’å¼åœæ­¢è„šæœ¬"""
        if not self.running_processes:
            print("âš ï¸ æ²¡æœ‰è¿è¡Œä¸­çš„è„šæœ¬")
            return
        
        print("\\nè¿è¡Œä¸­çš„è„šæœ¬:")
        for i, script_name in enumerate(self.running_processes.keys(), 1):
            print(f"{{i}}. {{script_name}}")
        
        try:
            choice = int(input("é€‰æ‹©è¦åœæ­¢çš„è„šæœ¬: "))
            script_names = list(self.running_processes.keys())
            
            if 1 <= choice <= len(script_names):
                script_name = script_names[choice - 1]
                if self.stop_script(script_name):
                    print(f"âœ… è„šæœ¬ {{script_name}} å·²åœæ­¢")
                else:
                    print(f"âŒ è„šæœ¬ {{script_name}} åœæ­¢å¤±è´¥")
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
    
    def _show_script_status(self):
        """æ˜¾ç¤ºè„šæœ¬çŠ¶æ€"""
        status = self.get_script_status()
        
        if not status:
            print("âš ï¸ æ²¡æœ‰è¿è¡Œä¸­çš„è„šæœ¬")
            return
        
        print("\\nğŸ“Š è„šæœ¬çŠ¶æ€:")
        for script_name, script_status in status.items():
            emoji = "ğŸŸ¢" if script_status == "running" else "ğŸ”´"
            print(f"  {{emoji}} {{script_name}}: {{script_status}}")
    
    def _show_health_check(self):
        """æ˜¾ç¤ºå¥åº·æ£€æŸ¥ç»“æœ"""
        health = self.health_check()
        
        print(f"\\nğŸ¥ ç³»ç»Ÿå¥åº·æ£€æŸ¥ - {{health['overall_status'].upper()}}")
        print(f"æ£€æŸ¥æ—¶é—´: {{health['timestamp']}}")
        print("\\nè¯¦ç»†æ£€æŸ¥ç»“æœ:")
        
        for check_name, check_result in health["checks"].items():
            status_emoji = {{"ok": "âœ…", "warning": "âš ï¸", "error": "âŒ"}}
            emoji = status_emoji.get(check_result["status"], "â“")
            print(f"  {{emoji}} {{check_name.replace('_', ' ').title()}}: {{check_result['status']}}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ç»Ÿä¸€è„šæœ¬ç®¡ç†å™¨")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºæ‰€æœ‰è„šæœ¬")
    parser.add_argument("--run", help="è¿è¡ŒæŒ‡å®šè„šæœ¬")
    parser.add_argument("--stop", help="åœæ­¢æŒ‡å®šè„šæœ¬")
    parser.add_argument("--status", action="store_true", help="æ˜¾ç¤ºè„šæœ¬çŠ¶æ€")
    parser.add_argument("--health", action="store_true", help="ç³»ç»Ÿå¥åº·æ£€æŸ¥")
    parser.add_argument("--interactive", "-i", action="store_true", help="äº¤äº’å¼æ¨¡å¼")
    
    args = parser.parse_args()
    
    manager = UnifiedScriptManager()
    
    if args.list:
        scripts = manager.list_scripts()
        print(json.dumps(scripts, indent=2))
        
    elif args.run:
        success = manager.run_script(args.run)
        sys.exit(0 if success else 1)
        
    elif args.stop:
        success = manager.stop_script(args.stop)
        sys.exit(0 if success else 1)
        
    elif args.status:
        status = manager.get_script_status()
        print(json.dumps(status, indent=2))
        
    elif args.health:
        health = manager.health_check()
        print(json.dumps(health, indent=2))
        
    elif args.interactive:
        manager.interactive_menu()
        
    else:
        manager.interactive_menu()

if __name__ == "__main__":
    main()
'''.format(
            timestamp=datetime.now().isoformat(),
            script_categories=json.dumps(self._generate_script_categories(), indent=8)
        )
        
        manager_path = self.management_dir / "unified_script_manager.py"
        with open(manager_path, 'w', encoding='utf-8') as f:
            f.write(unified_manager)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        os.chmod(manager_path, 0o755)
        
        self.log_action("ç»Ÿä¸€è„šæœ¬ç®¡ç†å™¨åˆ›å»ºå®Œæˆ", f"ç®¡ç†å™¨ä¿å­˜åˆ° {manager_path}")
    
    def _generate_script_categories(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆè„šæœ¬åˆ†ç±»"""
        categories = {}
        
        if hasattr(self, 'script_analysis') and 'script_functions' in self.script_analysis:
            for script_name, analysis in self.script_analysis['script_functions'].items():
                function_type = analysis.get('function_type', 'utility')
                
                if function_type not in categories:
                    categories[function_type] = []
                
                # ç§»é™¤æ‰©å±•å
                script_base_name = Path(script_name).stem
                categories[function_type].append(script_base_name)
        
        return categories
    
    def create_automated_deployment_system(self):
        """åˆ›å»ºè‡ªåŠ¨åŒ–éƒ¨ç½²ç³»ç»Ÿ"""
        self.log_action("åˆ›å»ºè‡ªåŠ¨åŒ–éƒ¨ç½²ç³»ç»Ÿ", "è®¾ç½®CI/CDæµç¨‹å’Œè‡ªåŠ¨åŒ–éƒ¨ç½²")
        
        # åˆ›å»ºéƒ¨ç½²é…ç½®
        deployment_config = {
            "deployment": {
                "environments": {
                    "development": {
                        "auto_deploy": True,
                        "branch": "develop",
                        "health_check": True,
                        "rollback_on_failure": True
                    },
                    "staging": {
                        "auto_deploy": False,
                        "branch": "staging",
                        "health_check": True,
                        "rollback_on_failure": True,
                        "approval_required": True
                    },
                    "production": {
                        "auto_deploy": False,
                        "branch": "main",
                        "health_check": True,
                        "rollback_on_failure": True,
                        "approval_required": True,
                        "backup_before_deploy": True
                    }
                },
                "steps": [
                    "pre_deployment_checks",
                    "backup_current_version",
                    "deploy_new_version",
                    "run_health_checks",
                    "post_deployment_tasks"
                ],
                "notifications": {
                    "on_success": True,
                    "on_failure": True,
                    "channels": ["log", "console"]
                }
            },
            "monitoring": {
                "health_check_interval": 300,  # 5åˆ†é’Ÿ
                "metrics_collection": True,
                "log_aggregation": True,
                "alert_thresholds": {
                    "cpu_usage": 80,
                    "memory_usage": 85,
                    "disk_usage": 90,
                    "response_time": 5000  # ms
                }
            }
        }
        
        config_path = self.config_dir / "deployment_config.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(deployment_config, f, default_flow_style=False, allow_unicode=True)
        
        # åˆ›å»ºéƒ¨ç½²è„šæœ¬
        self._create_deployment_script()
        
        self.log_action("è‡ªåŠ¨åŒ–éƒ¨ç½²ç³»ç»Ÿåˆ›å»ºå®Œæˆ", f"é…ç½®ä¿å­˜åˆ° {config_path}")
    
    def _create_deployment_script(self):
        """åˆ›å»ºéƒ¨ç½²è„šæœ¬"""
        deployment_script = '''#!/usr/bin/env python3
"""
ğŸš€ è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬
================

N.S.S-Novena-Garfieldé¡¹ç›®è‡ªåŠ¨åŒ–éƒ¨ç½²ç³»ç»Ÿ
- å¤šç¯å¢ƒéƒ¨ç½²æ”¯æŒ
- å¥åº·æ£€æŸ¥å’Œå›æ»š
- é€šçŸ¥å’Œæ—¥å¿—è®°å½•

è‡ªåŠ¨ç”Ÿæˆäº: {timestamp}
"""

import os
import sys
import json
import yaml
import subprocess
import time
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import shutil

class AutomatedDeployment:
    """è‡ªåŠ¨åŒ–éƒ¨ç½²ç³»ç»Ÿ"""
    
    def __init__(self, config_file: str = None):
        self.management_dir = Path(__file__).parent
        self.config_file = config_file or str(self.management_dir / "config" / "deployment_config.yaml")
        self.logs_dir = self.management_dir / "logs"
        
        # åŠ è½½é…ç½®
        self.config = self._load_config()
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # éƒ¨ç½²çŠ¶æ€
        self.deployment_status = {{
            "current_deployment": None,
            "last_deployment": None,
            "rollback_available": False
        }}
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½éƒ¨ç½²é…ç½®"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"Failed to load config: {{e}}")
            return {{}}
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        self.logs_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.logs_dir / 'deployment.log'),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger('AutomatedDeployment')
    
    def deploy(self, environment: str, version: str = None) -> bool:
        """æ‰§è¡Œéƒ¨ç½²"""
        if environment not in self.config.get("deployment", {{}}).get("environments", {{}}):
            self.logger.error(f"Unknown environment: {{environment}}")
            return False
        
        env_config = self.config["deployment"]["environments"][environment]
        
        self.logger.info(f"Starting deployment to {{environment}}")
        
        try:
            # æ‰§è¡Œéƒ¨ç½²æ­¥éª¤
            for step in self.config["deployment"]["steps"]:
                if not self._execute_deployment_step(step, environment, env_config):
                    self.logger.error(f"Deployment step failed: {{step}}")
                    
                    if env_config.get("rollback_on_failure", False):
                        self.rollback(environment)
                    
                    return False
            
            # æ›´æ–°éƒ¨ç½²çŠ¶æ€
            self.deployment_status["last_deployment"] = {{
                "environment": environment,
                "version": version,
                "timestamp": datetime.now().isoformat(),
                "status": "success"
            }}
            
            self.logger.info(f"Deployment to {{environment}} completed successfully")
            self._send_notification("success", environment, version)
            
            return True
            
        except Exception as e:
            self.logger.error(f"Deployment failed: {{e}}")
            self._send_notification("failure", environment, version, str(e))
            return False
    
    def _execute_deployment_step(self, step: str, environment: str, env_config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œå•ä¸ªéƒ¨ç½²æ­¥éª¤"""
        self.logger.info(f"Executing step: {{step}}")
        
        if step == "pre_deployment_checks":
            return self._pre_deployment_checks(environment)
            
        elif step == "backup_current_version":
            return self._backup_current_version(environment)
            
        elif step == "deploy_new_version":
            return self._deploy_new_version(environment, env_config)
            
        elif step == "run_health_checks":
            return self._run_health_checks(environment)
            
        elif step == "post_deployment_tasks":
            return self._post_deployment_tasks(environment)
            
        else:
            self.logger.warning(f"Unknown deployment step: {{step}}")
            return True
    
    def _pre_deployment_checks(self, environment: str) -> bool:
        """éƒ¨ç½²å‰æ£€æŸ¥"""
        # æ£€æŸ¥ç³»ç»Ÿèµ„æº
        disk_usage = shutil.disk_usage(self.management_dir)
        free_gb = disk_usage.free / (1024**3)
        
        if free_gb < 1:  # è‡³å°‘éœ€è¦1GBç©ºé—²ç©ºé—´
            self.logger.error(f"Insufficient disk space: {{free_gb:.2f}}GB")
            return False
        
        # æ£€æŸ¥å¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶
        required_paths = [
            self.management_dir / "scripts",
            self.management_dir / "config"
        ]
        
        for path in required_paths:
            if not path.exists():
                self.logger.error(f"Required path missing: {{path}}")
                return False
        
        self.logger.info("Pre-deployment checks passed")
        return True
    
    def _backup_current_version(self, environment: str) -> bool:
        """å¤‡ä»½å½“å‰ç‰ˆæœ¬"""
        backup_dir = self.management_dir / "backups" / f"{{environment}}_{{datetime.now().strftime('%Y%m%d_%H%M%S')}}"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # å¤‡ä»½å…³é”®ç›®å½•
            for dir_name in ["scripts", "config"]:
                src_dir = self.management_dir / dir_name
                if src_dir.exists():
                    dst_dir = backup_dir / dir_name
                    shutil.copytree(src_dir, dst_dir)
            
            self.deployment_status["rollback_available"] = True
            self.deployment_status["backup_path"] = str(backup_dir)
            
            self.logger.info(f"Backup created: {{backup_dir}}")
            return True
            
        except Exception as e:
            self.logger.error(f"Backup failed: {{e}}")
            return False
    
    def _deploy_new_version(self, environment: str, env_config: Dict[str, Any]) -> bool:
        """éƒ¨ç½²æ–°ç‰ˆæœ¬"""
        # è¿™é‡Œå®ç°å…·ä½“çš„éƒ¨ç½²é€»è¾‘
        # ä¾‹å¦‚ï¼šæ‹‰å–ä»£ç ã€æ›´æ–°é…ç½®ã€é‡å¯æœåŠ¡ç­‰
        
        self.logger.info(f"Deploying to {{environment}}")
        
        # æ¨¡æ‹Ÿéƒ¨ç½²è¿‡ç¨‹
        time.sleep(2)
        
        self.logger.info("New version deployed")
        return True
    
    def _run_health_checks(self, environment: str) -> bool:
        """è¿è¡Œå¥åº·æ£€æŸ¥"""
        # å®ç°å¥åº·æ£€æŸ¥é€»è¾‘
        self.logger.info("Running health checks")
        
        # æ¨¡æ‹Ÿå¥åº·æ£€æŸ¥
        time.sleep(1)
        
        self.logger.info("Health checks passed")
        return True
    
    def _post_deployment_tasks(self, environment: str) -> bool:
        """éƒ¨ç½²åä»»åŠ¡"""
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ã€æ›´æ–°æ–‡æ¡£ç­‰
        self.logger.info("Running post-deployment tasks")
        
        # æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™æœ€è¿‘5ä¸ªï¼‰
        self._cleanup_old_backups()
        
        self.logger.info("Post-deployment tasks completed")
        return True
    
    def _cleanup_old_backups(self):
        """æ¸…ç†æ—§å¤‡ä»½"""
        backups_dir = self.management_dir / "backups"
        if not backups_dir.exists():
            return
        
        # è·å–æ‰€æœ‰å¤‡ä»½ç›®å½•ï¼ŒæŒ‰æ—¶é—´æ’åº
        backup_dirs = [d for d in backups_dir.iterdir() if d.is_dir()]
        backup_dirs.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        # ä¿ç•™æœ€è¿‘5ä¸ªå¤‡ä»½
        for old_backup in backup_dirs[5:]:
            try:
                shutil.rmtree(old_backup)
                self.logger.info(f"Removed old backup: {{old_backup}}")
            except Exception as e:
                self.logger.warning(f"Failed to remove backup {{old_backup}}: {{e}}")
    
    def rollback(self, environment: str) -> bool:
        """å›æ»šåˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬"""
        if not self.deployment_status.get("rollback_available", False):
            self.logger.error("No backup available for rollback")
            return False
        
        backup_path = Path(self.deployment_status.get("backup_path", ""))
        if not backup_path.exists():
            self.logger.error(f"Backup path not found: {{backup_path}}")
            return False
        
        try:
            self.logger.info(f"Rolling back {{environment}} from {{backup_path}}")
            
            # æ¢å¤å¤‡ä»½
            for dir_name in ["scripts", "config"]:
                src_dir = backup_path / dir_name
                dst_dir = self.management_dir / dir_name
                
                if src_dir.exists():
                    if dst_dir.exists():
                        shutil.rmtree(dst_dir)
                    shutil.copytree(src_dir, dst_dir)
            
            self.logger.info("Rollback completed successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Rollback failed: {{e}}")
            return False
    
    def _send_notification(self, status: str, environment: str, version: str = None, error: str = None):
        """å‘é€é€šçŸ¥"""
        notification_config = self.config.get("deployment", {{}}).get("notifications", {{}})
        
        if not notification_config.get(f"on_{{status}}", False):
            return
        
        message = f"Deployment to {{environment}} {{status}}"
        if version:
            message += f" (version: {{version}})"
        if error:
            message += f" - Error: {{error}}"
        
        # å‘é€åˆ°é…ç½®çš„é€šçŸ¥æ¸ é“
        for channel in notification_config.get("channels", []):
            if channel == "log":
                self.logger.info(f"NOTIFICATION: {{message}}")
            elif channel == "console":
                print(f"ğŸ“¢ {{message}}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è‡ªåŠ¨åŒ–éƒ¨ç½²ç³»ç»Ÿ")
    parser.add_argument("--environment", "-e", required=True, help="éƒ¨ç½²ç¯å¢ƒ")
    parser.add_argument("--version", "-v", help="ç‰ˆæœ¬å·")
    parser.add_argument("--rollback", action="store_true", help="å›æ»šåˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬")
    parser.add_argument("--config", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    deployment = AutomatedDeployment(args.config)
    
    if args.rollback:
        success = deployment.rollback(args.environment)
    else:
        success = deployment.deploy(args.environment, args.version)
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
'''.format(timestamp=datetime.now().isoformat())
        
        script_path = self.management_dir / "automated_deployment.py"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(deployment_script)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        os.chmod(script_path, 0o755)
        
        self.log_action("è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬åˆ›å»ºå®Œæˆ", f"è„šæœ¬ä¿å­˜åˆ° {script_path}")
    
    def create_monitoring_system(self):
        """åˆ›å»ºç³»ç»Ÿç›‘æ§"""
        self.log_action("åˆ›å»ºç³»ç»Ÿç›‘æ§", "è®¾ç½®å…¨é¢çš„ç³»ç»Ÿç›‘æ§å’Œå‘Šè­¦")
        
        # åˆ›å»ºç›‘æ§é…ç½®
        monitoring_config = {
            "monitoring": {
                "enabled": True,
                "interval": 60,  # ç§’
                "metrics": {
                    "system": {
                        "cpu_usage": True,
                        "memory_usage": True,
                        "disk_usage": True,
                        "network_io": True
                    },
                    "application": {
                        "process_count": True,
                        "response_time": True,
                        "error_rate": True,
                        "log_errors": True
                    }
                },
                "alerts": {
                    "cpu_threshold": 80,
                    "memory_threshold": 85,
                    "disk_threshold": 90,
                    "error_rate_threshold": 5  # %
                },
                "retention": {
                    "metrics": "7d",
                    "logs": "30d",
                    "alerts": "90d"
                }
            }
        }
        
        config_path = self.config_dir / "monitoring_config.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(monitoring_config, f, default_flow_style=False, allow_unicode=True)
        
        # åˆ›å»ºç›‘æ§è„šæœ¬
        self._create_monitoring_script()
        
        self.log_action("ç³»ç»Ÿç›‘æ§åˆ›å»ºå®Œæˆ", f"é…ç½®ä¿å­˜åˆ° {config_path}")
    
    def _create_monitoring_script(self):
        """åˆ›å»ºç›‘æ§è„šæœ¬"""
        monitoring_script = '''#!/usr/bin/env python3
"""
ğŸ“Š ç³»ç»Ÿç›‘æ§è„šæœ¬
==============

N.S.S-Novena-Garfieldé¡¹ç›®ç³»ç»Ÿç›‘æ§
- ç³»ç»Ÿèµ„æºç›‘æ§
- åº”ç”¨æ€§èƒ½ç›‘æ§
- å‘Šè­¦å’Œé€šçŸ¥
- æ•°æ®æ”¶é›†å’Œåˆ†æ

è‡ªåŠ¨ç”Ÿæˆäº: {timestamp}
"""

import os
import sys
import json
import yaml
import time
import psutil
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import threading
import queue

class SystemMonitor:
    """ç³»ç»Ÿç›‘æ§å™¨"""
    
    def __init__(self, config_file: str = None):
        self.management_dir = Path(__file__).parent
        self.config_file = config_file or str(self.management_dir / "config" / "monitoring_config.yaml")
        self.logs_dir = self.management_dir / "logs"
        self.metrics_dir = self.management_dir / "metrics"
        
        # åˆ›å»ºç›®å½•
        self.metrics_dir.mkdir(exist_ok=True)
        
        # åŠ è½½é…ç½®
        self.config = self._load_config()
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # ç›‘æ§çŠ¶æ€
        self.monitoring_active = False
        self.metrics_queue = queue.Queue()
        self.alert_history = []
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½ç›‘æ§é…ç½®"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"Failed to load config: {{e}}")
            return {{}}
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        self.logs_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.logs_dir / 'monitoring.log'),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger('SystemMonitor')
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.monitoring_active:
            self.logger.warning("Monitoring is already active")
            return
        
        self.monitoring_active = True
        self.logger.info("Starting system monitoring")
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        monitor_thread.start()
        
        # å¯åŠ¨æŒ‡æ ‡å¤„ç†çº¿ç¨‹
        metrics_thread = threading.Thread(target=self._metrics_processor, daemon=True)
        metrics_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring_active = False
        self.logger.info("Stopping system monitoring")
    
    def _monitoring_loop(self):
        """ç›‘æ§ä¸»å¾ªç¯"""
        interval = self.config.get("monitoring", {{}}).get("interval", 60)
        
        while self.monitoring_active:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                metrics = self._collect_system_metrics()
                
                # æ”¶é›†åº”ç”¨æŒ‡æ ‡
                app_metrics = self._collect_application_metrics()
                metrics.update(app_metrics)
                
                # æ·»åŠ æ—¶é—´æˆ³
                metrics["timestamp"] = datetime.now().isoformat()
                
                # æ”¾å…¥é˜Ÿåˆ—å¤„ç†
                self.metrics_queue.put(metrics)
                
                # æ£€æŸ¥å‘Šè­¦
                self._check_alerts(metrics)
                
                time.sleep(interval)
                
            except Exception as e:
                self.logger.error(f"Monitoring loop error: {{e}}")
                time.sleep(interval)
    
    def _collect_system_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        metrics = {{}}
        
        system_config = self.config.get("monitoring", {{}}).get("metrics", {{}}).get("system", {{}})
        
        if system_config.get("cpu_usage", False):
            metrics["cpu_usage"] = psutil.cpu_percent(interval=1)
        
        if system_config.get("memory_usage", False):
            memory = psutil.virtual_memory()
            metrics["memory_usage"] = {{
                "percent": memory.percent,
                "available_gb": memory.available / (1024**3),
                "used_gb": memory.used / (1024**3)
            }}
        
        if system_config.get("disk_usage", False):
            disk = psutil.disk_usage(self.management_dir)
            metrics["disk_usage"] = {{
                "percent": (disk.used / disk.total) * 100,
                "free_gb": disk.free / (1024**3),
                "used_gb": disk.used / (1024**3)
            }}
        
        if system_config.get("network_io", False):
            network = psutil.net_io_counters()
            metrics["network_io"] = {{
                "bytes_sent": network.bytes_sent,
                "bytes_recv": network.bytes_recv,
                "packets_sent": network.packets_sent,
                "packets_recv": network.packets_recv
            }}
        
        return metrics
    
    def _collect_application_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†åº”ç”¨æŒ‡æ ‡"""
        metrics = {{}}
        
        app_config = self.config.get("monitoring", {{}}).get("metrics", {{}}).get("application", {{}})
        
        if app_config.get("process_count", False):
            # ç»Ÿè®¡Pythonè¿›ç¨‹æ•°é‡
            python_processes = [p for p in psutil.process_iter(['name']) if 'python' in p.info['name'].lower()]
            metrics["process_count"] = {{
                "python_processes": len(python_processes),
                "total_processes": len(list(psutil.process_iter()))
            }}
        
        if app_config.get("log_errors", False):
            # ç»Ÿè®¡æ—¥å¿—é”™è¯¯
            error_count = self._count_recent_log_errors()
            metrics["log_errors"] = error_count
        
        return metrics
    
    def _count_recent_log_errors(self) -> int:
        """ç»Ÿè®¡æœ€è¿‘çš„æ—¥å¿—é”™è¯¯"""
        error_count = 0
        
        try:
            # æ£€æŸ¥æœ€è¿‘1å°æ—¶çš„æ—¥å¿—é”™è¯¯
            cutoff_time = datetime.now() - timedelta(hours=1)
            
            for log_file in self.logs_dir.glob("*.log"):
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        for line in f:
                            if "ERROR" in line or "CRITICAL" in line:
                                # ç®€å•çš„æ—¶é—´è§£æï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦æ›´ç²¾ç¡®çš„è§£æï¼‰
                                if cutoff_time.strftime("%Y-%m-%d") in line:
                                    error_count += 1
                except Exception:
                    continue
                    
        except Exception as e:
            self.logger.warning(f"Failed to count log errors: {{e}}")
        
        return error_count
    
    def _check_alerts(self, metrics: Dict[str, Any]):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        alerts_config = self.config.get("monitoring", {{}}).get("alerts", {{}})
        
        alerts = []
        
        # CPUä½¿ç”¨ç‡å‘Šè­¦
        cpu_usage = metrics.get("cpu_usage", 0)
        cpu_threshold = alerts_config.get("cpu_threshold", 80)
        if cpu_usage > cpu_threshold:
            alerts.append({{
                "type": "cpu_high",
                "message": f"High CPU usage: {{cpu_usage:.1f}}%",
                "severity": "warning" if cpu_usage < 90 else "critical",
                "value": cpu_usage,
                "threshold": cpu_threshold
            }})
        
        # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
        memory_usage = metrics.get("memory_usage", {{}}).get("percent", 0)
        memory_threshold = alerts_config.get("memory_threshold", 85)
        if memory_usage > memory_threshold:
            alerts.append({{
                "type": "memory_high",
                "message": f"High memory usage: {{memory_usage:.1f}}%",
                "severity": "warning" if memory_usage < 95 else "critical",
                "value": memory_usage,
                "threshold": memory_threshold
            }})
        
        # ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦
        disk_usage = metrics.get("disk_usage", {{}}).get("percent", 0)
        disk_threshold = alerts_config.get("disk_threshold", 90)
        if disk_usage > disk_threshold:
            alerts.append({{
                "type": "disk_high",
                "message": f"High disk usage: {{disk_usage:.1f}}%",
                "severity": "warning" if disk_usage < 95 else "critical",
                "value": disk_usage,
                "threshold": disk_threshold
            }})
        
        # æ—¥å¿—é”™è¯¯å‘Šè­¦
        log_errors = metrics.get("log_errors", 0)
        error_threshold = alerts_config.get("error_rate_threshold", 5)
        if log_errors > error_threshold:
            alerts.append({{
                "type": "log_errors_high",
                "message": f"High error rate: {{log_errors}} errors in last hour",
                "severity": "warning",
                "value": log_errors,
                "threshold": error_threshold
            }})
        
        # å¤„ç†å‘Šè­¦
        for alert in alerts:
            self._handle_alert(alert)
    
    def _handle_alert(self, alert: Dict[str, Any]):
        """å¤„ç†å‘Šè­¦"""
        alert["timestamp"] = datetime.now().isoformat()
        
        # é¿å…é‡å¤å‘Šè­¦
        recent_alerts = [a for a in self.alert_history if 
                        a["type"] == alert["type"] and 
                        datetime.fromisoformat(a["timestamp"]) > datetime.now() - timedelta(minutes=10)]
        
        if recent_alerts:
            return  # 10åˆ†é’Ÿå†…å·²æœ‰ç›¸åŒå‘Šè­¦
        
        # è®°å½•å‘Šè­¦
        self.alert_history.append(alert)
        
        # å‘é€å‘Šè­¦
        self.logger.warning(f"ALERT [{{alert['severity'].upper()}}]: {{alert['message']}}")
        
        # ä¿å­˜å‘Šè­¦åˆ°æ–‡ä»¶
        self._save_alert(alert)
    
    def _save_alert(self, alert: Dict[str, Any]):
        """ä¿å­˜å‘Šè­¦åˆ°æ–‡ä»¶"""
        alerts_file = self.logs_dir / "alerts.jsonl"
        
        try:
            with open(alerts_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(alert) + '\\n')
        except Exception as e:
            self.logger.error(f"Failed to save alert: {{e}}")
    
    def _metrics_processor(self):
        """æŒ‡æ ‡å¤„ç†å™¨"""
        while self.monitoring_active:
            try:
                # ä»é˜Ÿåˆ—è·å–æŒ‡æ ‡
                metrics = self.metrics_queue.get(timeout=1)
                
                # ä¿å­˜æŒ‡æ ‡
                self._save_metrics(metrics)
                
                # æ¸…ç†æ—§æŒ‡æ ‡
                self._cleanup_old_metrics()
                
            except queue.Empty:
                continue
            except Exception as e:
                self.logger.error(f"Metrics processor error: {{e}}")
    
    def _save_metrics(self, metrics: Dict[str, Any]):
        """ä¿å­˜æŒ‡æ ‡æ•°æ®"""
        # æŒ‰æ—¥æœŸä¿å­˜æŒ‡æ ‡
        date_str = datetime.now().strftime("%Y-%m-%d")
        metrics_file = self.metrics_dir / f"metrics_{{date_str}}.jsonl"
        
        try:
            with open(metrics_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(metrics) + '\\n')
        except Exception as e:
            self.logger.error(f"Failed to save metrics: {{e}}")
    
    def _cleanup_old_metrics(self):
        """æ¸…ç†æ—§æŒ‡æ ‡æ–‡ä»¶"""
        retention_days = 7  # ä¿ç•™7å¤©çš„æŒ‡æ ‡æ•°æ®
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        
        for metrics_file in self.metrics_dir.glob("metrics_*.jsonl"):
            try:
                file_date_str = metrics_file.stem.replace("metrics_", "")
                file_date = datetime.strptime(file_date_str, "%Y-%m-%d")
                
                if file_date < cutoff_date:
                    metrics_file.unlink()
                    self.logger.info(f"Removed old metrics file: {{metrics_file}}")
                    
            except Exception as e:
                self.logger.warning(f"Failed to process metrics file {{metrics_file}}: {{e}}")
    
    def get_current_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç›‘æ§çŠ¶æ€"""
        return {{
            "monitoring_active": self.monitoring_active,
            "recent_alerts": self.alert_history[-10:],  # æœ€è¿‘10ä¸ªå‘Šè­¦
            "metrics_queue_size": self.metrics_queue.qsize(),
            "uptime": "monitoring_active_since_start"  # å®é™…åº”ç”¨ä¸­åº”è¯¥è®°å½•å¯åŠ¨æ—¶é—´
        }}

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç³»ç»Ÿç›‘æ§")
    parser.add_argument("--config", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--daemon", action="store_true", help="åå°è¿è¡Œ")
    parser.add_argument("--status", action="store_true", help="æ˜¾ç¤ºç›‘æ§çŠ¶æ€")
    
    args = parser.parse_args()
    
    monitor = SystemMonitor(args.config)
    
    if args.status:
        status = monitor.get_current_status()
        print(json.dumps(status, indent=2))
        return
    
    # å¯åŠ¨ç›‘æ§
    monitor.start_monitoring()
    
    if args.daemon:
        # åå°è¿è¡Œ
        try:
            while True:
                time.sleep(60)
        except KeyboardInterrupt:
            monitor.stop_monitoring()
    else:
        # äº¤äº’å¼è¿è¡Œ
        print("ç›‘æ§å·²å¯åŠ¨ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            monitor.stop_monitoring()
            print("\\nç›‘æ§å·²åœæ­¢")

if __name__ == "__main__":
    main()
'''.format(timestamp=datetime.now().isoformat())
        
        script_path = self.management_dir / "system_monitor.py"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(monitoring_script)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        os.chmod(script_path, 0o755)
        
        self.log_action("ç³»ç»Ÿç›‘æ§è„šæœ¬åˆ›å»ºå®Œæˆ", f"è„šæœ¬ä¿å­˜åˆ° {script_path}")
    
    def create_unified_logging_system(self):
        """åˆ›å»ºç»Ÿä¸€æ—¥å¿—ç®¡ç†ç³»ç»Ÿ"""
        self.log_action("åˆ›å»ºç»Ÿä¸€æ—¥å¿—ç®¡ç†", "è®¾ç½®é›†ä¸­åŒ–æ—¥å¿—æ”¶é›†å’Œåˆ†æ")
        
        # åˆ›å»ºæ—¥å¿—é…ç½®
        logging_config = {
            "logging": {
                "version": 1,
                "disable_existing_loggers": False,
                "formatters": {
                    "standard": {
                        "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
                    },
                    "detailed": {
                        "format": "%(asctime)s - %(name)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s"
                    },
                    "json": {
                        "format": "%(asctime)s %(name)s %(levelname)s %(message)s",
                        "class": "pythonjsonlogger.jsonlogger.JsonFormatter"
                    }
                },
                "handlers": {
                    "console": {
                        "class": "logging.StreamHandler",
                        "level": "INFO",
                        "formatter": "standard",
                        "stream": "ext://sys.stdout"
                    },
                    "file": {
                        "class": "logging.handlers.RotatingFileHandler",
                        "level": "DEBUG",
                        "formatter": "detailed",
                        "filename": "logs/application.log",
                        "maxBytes": 10485760,  # 10MB
                        "backupCount": 5
                    },
                    "error_file": {
                        "class": "logging.handlers.RotatingFileHandler",
                        "level": "ERROR",
                        "formatter": "detailed",
                        "filename": "logs/errors.log",
                        "maxBytes": 10485760,
                        "backupCount": 5
                    }
                },
                "loggers": {
                    "": {
                        "handlers": ["console", "file", "error_file"],
                        "level": "DEBUG",
                        "propagate": False
                    }
                }
            },
            "log_aggregation": {
                "enabled": True,
                "sources": [
                    "logs/*.log",
                    "systems/*/logs/*.log",
                    "api/logs/*.log"
                ],
                "retention_days": 30,
                "compression": True
            }
        }
        
        config_path = self.config_dir / "logging_config.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(logging_config, f, default_flow_style=False, allow_unicode=True)
        
        self.log_action("ç»Ÿä¸€æ—¥å¿—ç®¡ç†åˆ›å»ºå®Œæˆ", f"é…ç½®ä¿å­˜åˆ° {config_path}")
    
    def create_optimization_report(self):
        """åˆ›å»ºä¼˜åŒ–æŠ¥å‘Š"""
        report = {
            "optimization_date": datetime.now().isoformat(),
            "management_directory": str(self.management_dir),
            "actions_performed": self.optimization_log,
            "script_analysis": self.script_analysis,
            "automation_metrics": self.automation_metrics,
            "summary": {
                "total_actions": len(self.optimization_log),
                "scripts_analyzed": self.script_analysis.get("total_scripts", 0),
                "redundancy_percentage": self.script_analysis.get("redundancy_percentage", 0),
                "unified_manager_created": any("ç»Ÿä¸€è„šæœ¬ç®¡ç†å™¨" in action["action"] for action in self.optimization_log),
                "deployment_system_created": any("è‡ªåŠ¨åŒ–éƒ¨ç½²" in action["action"] for action in self.optimization_log),
                "monitoring_system_created": any("ç³»ç»Ÿç›‘æ§" in action["action"] for action in self.optimization_log),
                "logging_system_created": any("æ—¥å¿—ç®¡ç†" in action["action"] for action in self.optimization_log)
            },
            "recommendations": self._generate_final_recommendations()
        }
        
        report_file = self.management_dir / "management_optimization_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        self.log_action("ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š", f"æŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")
        
        return report
    
    def _generate_final_recommendations(self) -> List[str]:
        """ç”Ÿæˆæœ€ç»ˆå»ºè®®"""
        recommendations = []
        
        # åŸºäºè„šæœ¬åˆ†æç”Ÿæˆå»ºè®®
        if self.script_analysis:
            redundancy_percentage = self.script_analysis.get("redundancy_percentage", 0)
            if redundancy_percentage > 30:
                recommendations.append(f"è„šæœ¬å†—ä½™ç‡è¾ƒé«˜({redundancy_percentage:.1f}%)ï¼Œå»ºè®®è¿›ä¸€æ­¥æ•´åˆ")
            
            total_scripts = self.script_analysis.get("total_scripts", 0)
            if total_scripts > 20:
                recommendations.append(f"è„šæœ¬æ•°é‡è¾ƒå¤š({total_scripts}ä¸ª)ï¼Œå»ºè®®æŒ‰åŠŸèƒ½æ¨¡å—é‡æ–°ç»„ç»‡")
        
        # é€šç”¨å»ºè®®
        recommendations.extend([
            "å®šæœŸè¿è¡Œç³»ç»Ÿç›‘æ§ä»¥ç¡®ä¿æ€§èƒ½ç¨³å®š",
            "å®æ–½è‡ªåŠ¨åŒ–éƒ¨ç½²ä»¥æé«˜å‘å¸ƒæ•ˆç‡",
            "å»ºç«‹å®Œå–„çš„æ—¥å¿—åˆ†æå’Œå‘Šè­¦æœºåˆ¶",
            "å®šæœŸæ¸…ç†å’Œå½’æ¡£æ—§çš„æ—¥å¿—å’ŒæŒ‡æ ‡æ•°æ®",
            "è€ƒè™‘å®æ–½å®¹å™¨åŒ–éƒ¨ç½²ä»¥æé«˜å¯ç§»æ¤æ€§"
        ])
        
        return recommendations
    
    def run_optimization(self):
        """è¿è¡Œå®Œæ•´ä¼˜åŒ–æµç¨‹"""
        print("ğŸ“‹ å¼€å§‹Managementç³»ç»Ÿè‡ªåŠ¨åŒ–ä¼˜åŒ–...")
        print("=" * 70)
        
        # 1. åˆ†æè„šæœ¬å†—ä½™
        self.analyze_script_redundancy()
        
        # 2. åˆ›å»ºç»Ÿä¸€è„šæœ¬ç®¡ç†å™¨
        self.create_unified_script_manager()
        
        # 3. åˆ›å»ºè‡ªåŠ¨åŒ–éƒ¨ç½²ç³»ç»Ÿ
        self.create_automated_deployment_system()
        
        # 4. åˆ›å»ºç³»ç»Ÿç›‘æ§
        self.create_monitoring_system()
        
        # 5. åˆ›å»ºç»Ÿä¸€æ—¥å¿—ç®¡ç†
        self.create_unified_logging_system()
        
        # 6. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        report = self.create_optimization_report()
        
        print("\n" + "=" * 70)
        print("ğŸ‰ Managementç³»ç»Ÿè‡ªåŠ¨åŒ–ä¼˜åŒ–å®Œæˆ!")
        print(f"ğŸ“Š æ‰§è¡Œäº† {report['summary']['total_actions']} ä¸ªä¼˜åŒ–æ“ä½œ")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {self.management_dir}/management_optimization_report.json")
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Managementç³»ç»Ÿè‡ªåŠ¨åŒ–ä¼˜åŒ–å·¥å…·")
    parser.add_argument("--management-dir", help="Managementç³»ç»Ÿç›®å½•è·¯å¾„")
    parser.add_argument("--dry-run", action="store_true", help="ä»…åˆ†æï¼Œä¸æ‰§è¡Œå®é™…ä¼˜åŒ–")
    
    args = parser.parse_args()
    
    management_dir = Path(args.management_dir) if args.management_dir else Path(__file__).parent
    
    if not management_dir.exists():
        print(f"âŒ Managementç›®å½•ä¸å­˜åœ¨: {management_dir}")
        return
    
    optimizer = ManagementOptimizer(management_dir)
    
    if args.dry_run:
        print("ğŸ” æ‰§è¡Œåˆ†ææ¨¡å¼ï¼ˆä¸ä¼šä¿®æ”¹æ–‡ä»¶ï¼‰...")
        optimizer.analyze_script_redundancy()
    else:
        optimizer.run_optimization()

if __name__ == "__main__":
    main()