#!/usr/bin/env python3
"""
ğŸ—ï¸ ä¿®æ­£ç‰ˆé¡¹ç›®æ¶æ„åˆ†æå™¨
========================

ä¿®æ­£ä¹‹å‰åŒ…å«node_moduleså¯¼è‡´çš„ä»£ç é‡ç»Ÿè®¡é”™è¯¯
å‡†ç¡®åˆ†æé¡¹ç›®æ¶æ„ã€åŠŸèƒ½æ¨¡å—å’Œä»£ç é‡
"""

import os
import json
from pathlib import Path
from typing import Dict, List, Any, Tuple
from datetime import datetime
import subprocess
import re

class CorrectedArchitectureAnalyzer:
    """ä¿®æ­£ç‰ˆé¡¹ç›®æ¶æ„åˆ†æå™¨"""
    
    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path(__file__).parent
        self.excluded_dirs = ["node_modules", "__pycache__", ".git", ".vscode", "dist", "build"]
        
    def should_exclude_path(self, path: Path) -> bool:
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
        path_str = str(path)
        return any(excluded in path_str for excluded in self.excluded_dirs)
    
    def get_filtered_files(self, root_path: Path, patterns: List[str]) -> List[Path]:
        """è·å–è¿‡æ»¤åçš„æ–‡ä»¶åˆ—è¡¨"""
        files = []
        for pattern in patterns:
            found_files = list(root_path.glob(f"**/{pattern}"))
            # è¿‡æ»¤æ‰æ’é™¤çš„ç›®å½•
            filtered_files = [f for f in found_files if not self.should_exclude_path(f)]
            files.extend(filtered_files)
        return files
    
    def count_lines_in_files(self, files: List[Path]) -> int:
        """ç»Ÿè®¡æ–‡ä»¶è¡Œæ•°"""
        total_lines = 0
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = len(f.readlines())
                    total_lines += lines
            except Exception:
                continue
        return total_lines
    
    def analyze_system_corrected(self, system_path: Path, system_name: str) -> Dict[str, Any]:
        """ä¿®æ­£ç‰ˆç³»ç»Ÿåˆ†æ"""
        print(f"  ğŸ“Š åˆ†æ {system_name}...")
        
        analysis = {
            "name": system_name,
            "path": str(system_path),
            "file_count": 0,
            "total_lines": 0,
            "file_types": {},
            "main_modules": [],
            "config_files": [],
            "optimization_files": []
        }
        
        if not system_path.exists():
            return analysis
        
        # ç»Ÿè®¡å„ç§æ–‡ä»¶ç±»å‹
        file_patterns = {
            "py": ["*.py"],
            "js": ["*.js"],
            "jsx": ["*.jsx"], 
            "ts": ["*.ts"],
            "html": ["*.html"],
            "css": ["*.css"],
            "json": ["*.json"],
            "md": ["*.md"],
            "sh": ["*.sh"],
            "yaml": ["*.yaml", "*.yml"]
        }
        
        for file_type, patterns in file_patterns.items():
            files = self.get_filtered_files(system_path, patterns)
            
            if files:
                analysis["file_types"][file_type] = len(files)
                analysis["file_count"] += len(files)
                
                # ç»Ÿè®¡ä»£ç è¡Œæ•°
                lines = self.count_lines_in_files(files)
                analysis["total_lines"] += lines
        
        # è¯†åˆ«ä¸»è¦æ¨¡å—ï¼ˆæ’é™¤node_modulesï¼‰
        main_patterns = ["main.py", "app.py", "server.py", "index.html", "index.js", "*_app.py", "unified_*.py"]
        main_files = self.get_filtered_files(system_path, main_patterns)
        analysis["main_modules"] = [f.name for f in main_files[:10]]
        
        # è¯†åˆ«é…ç½®æ–‡ä»¶
        config_patterns = ["config*.py", "config*.json", "config*.yaml", "package.json", "requirements.txt"]
        config_files = self.get_filtered_files(system_path, config_patterns)
        analysis["config_files"] = [f.name for f in config_files[:10]]
        
        # è¯†åˆ«ä¼˜åŒ–æ–‡ä»¶
        opt_patterns = ["*optimization*", "*unified*", "*optimize*", "*performance*", "*monitor*"]
        opt_files = self.get_filtered_files(system_path, opt_patterns)
        analysis["optimization_files"] = [f.name for f in opt_files[:10]]
        
        return analysis
    
    def generate_corrected_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆä¿®æ­£ç‰ˆåˆ†ææŠ¥å‘Š"""
        print("ğŸ” ç”Ÿæˆä¿®æ­£ç‰ˆæ¶æ„åˆ†ææŠ¥å‘Š...")
        
        report = {
            "project_name": "N.S.S-Novena-Garfield",
            "analysis_date": datetime.now().isoformat(),
            "note": "ä¿®æ­£ç‰ˆ - æ’é™¤node_modulesç­‰æ— å…³ç›®å½•",
            "project_root": str(self.project_root),
            "excluded_directories": self.excluded_dirs,
            "systems": {},
            "total_files": 0,
            "total_lines": 0,
            "language_stats": {}
        }
        
        # åˆ†æå„ä¸ªç³»ç»Ÿ
        systems_to_analyze = {
            "rag-system": "ğŸ§  RAGæ™ºèƒ½ç³»ç»Ÿ",
            "api": "ğŸŒ APIç®¡ç†ç³»ç»Ÿ", 
            "nexus": "ğŸ¯ Nexusæ§åˆ¶é¢æ¿",
            "chronicle": "ğŸ“š Chronicleç¼–å¹´å²",
            "Changlee": "ğŸ”„ Changleeæ¡Œé¢å® ç‰©",
            "management": "ğŸ“‹ Managementé¡¹ç›®ç®¡ç†"
        }
        
        for system_key, system_name in systems_to_analyze.items():
            if system_key == "api":
                system_path = self.project_root / "api"
            elif system_key == "management":
                system_path = self.project_root / "management"
            else:
                system_path = self.project_root / "systems" / system_key
            
            if system_path.exists():
                system_analysis = self.analyze_system_corrected(system_path, system_name)
                report["systems"][system_key] = system_analysis
                report["total_files"] += system_analysis["file_count"]
                report["total_lines"] += system_analysis["total_lines"]
        
        # ç»Ÿè®¡ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ
        language_mapping = {
            "Python": ["py"],
            "JavaScript": ["js", "jsx"],
            "TypeScript": ["ts"],
            "HTML": ["html"],
            "CSS": ["css"],
            "JSON": ["json"],
            "Markdown": ["md"],
            "Shell": ["sh"],
            "YAML": ["yaml"]
        }
        
        for language, extensions in language_mapping.items():
            total_lines = 0
            for system_data in report["systems"].values():
                for ext in extensions:
                    if ext in system_data["file_types"]:
                        # é‡æ–°è®¡ç®—è¯¥è¯­è¨€çš„è¡Œæ•°
                        system_path = Path(system_data["path"])
                        patterns = [f"*.{ext}"]
                        files = self.get_filtered_files(system_path, patterns)
                        lines = self.count_lines_in_files(files)
                        total_lines += lines
            
            if total_lines > 0:
                report["language_stats"][language] = total_lines
        
        return report
    
    def print_corrected_summary(self, report: Dict[str, Any]):
        """æ‰“å°ä¿®æ­£ç‰ˆåˆ†ææ‘˜è¦"""
        print("\n" + "="*80)
        print("ğŸ—ï¸ N.S.S-Novena-Garfield é¡¹ç›®æ¶æ„åˆ†ææ‘˜è¦ (ä¿®æ­£ç‰ˆ)")
        print("="*80)
        
        print(f"ğŸ“Š é¡¹ç›®æ¦‚è§ˆ:")
        print(f"  â€¢ æ€»æ–‡ä»¶æ•°: {report['total_files']:,} (æ’é™¤node_modulesç­‰)")
        print(f"  â€¢ æ€»ä»£ç è¡Œæ•°: {report['total_lines']:,}")
        print(f"  â€¢ ç³»ç»Ÿæ¨¡å—æ•°: {len(report['systems'])}")
        
        print(f"\nğŸ¯ å„ç³»ç»Ÿç»Ÿè®¡ (ä¿®æ­£å):")
        for system_key, system_data in report['systems'].items():
            print(f"  â€¢ {system_data['name']}: {system_data['file_count']} æ–‡ä»¶, {system_data['total_lines']:,} è¡Œ")
        
        print(f"\nğŸ’» ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡ (ä¿®æ­£å):")
        for language, lines in sorted(report['language_stats'].items(), key=lambda x: x[1], reverse=True):
            percentage = (lines / report['total_lines']) * 100 if report['total_lines'] > 0 else 0
            print(f"  â€¢ {language}: {lines:,} è¡Œ ({percentage:.1f}%)")
        
        print(f"\nğŸ“ æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
        file_type_totals = {}
        for system_data in report['systems'].values():
            for file_type, count in system_data['file_types'].items():
                file_type_totals[file_type] = file_type_totals.get(file_type, 0) + count
        
        for file_type, count in sorted(file_type_totals.items(), key=lambda x: x[1], reverse=True):
            print(f"  â€¢ {file_type.upper()}: {count} æ–‡ä»¶")
        
        # å¯¹æ¯”è¯´æ˜
        print(f"\nâš ï¸ ä¿®æ­£è¯´æ˜:")
        print(f"  â€¢ æ’é™¤äº† node_modules ç›®å½• (åŒ…å« 36,852 ä¸ªä¾èµ–æ–‡ä»¶)")
        print(f"  â€¢ æ’é™¤äº† __pycache__, .git ç­‰ç³»ç»Ÿç›®å½•")
        print(f"  â€¢ åªç»Ÿè®¡é¡¹ç›®æºä»£ç å’Œé…ç½®æ–‡ä»¶")
        print(f"  â€¢ Chronicleç³»ç»Ÿä» 221,745 è¡Œä¿®æ­£ä¸ºçº¦ 32,224 è¡Œ")
        print(f"  â€¢ æ€»ä»£ç é‡ä» 244,881 è¡Œä¿®æ­£ä¸º {report['total_lines']:,} è¡Œ")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = CorrectedArchitectureAnalyzer()
    
    print("ğŸš€ å¼€å§‹ä¿®æ­£ç‰ˆé¡¹ç›®æ¶æ„åˆ†æ...")
    
    # ç”Ÿæˆä¿®æ­£ç‰ˆåˆ†ææŠ¥å‘Š
    report = analyzer.generate_corrected_report()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = Path("corrected_architecture_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°æ‘˜è¦
    analyzer.print_corrected_summary(report)
    
    print(f"\nğŸ“„ ä¿®æ­£ç‰ˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

if __name__ == "__main__":
    main()